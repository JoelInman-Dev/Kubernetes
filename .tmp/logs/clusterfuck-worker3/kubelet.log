Apr 14 12:18:38 clusterfuck-worker3 systemd[1]: Condition check resulted in kubelet: The Kubernetes Node Agent being skipped.
Apr 14 12:19:20 clusterfuck-worker3 systemd[1]: Starting kubelet: The Kubernetes Node Agent...
Apr 14 12:19:20 clusterfuck-worker3 systemd[1]: Started kubelet: The Kubernetes Node Agent.
Apr 14 12:19:20 clusterfuck-worker3 kubelet[167]: Flag --pod-infra-container-image has been deprecated, will be removed in 1.27. Image garbage collector will get sandbox image information from CRI.
Apr 14 12:19:20 clusterfuck-worker3 kubelet[167]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:20 clusterfuck-worker3 kubelet[167]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:20 clusterfuck-worker3 kubelet[167]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:20 clusterfuck-worker3 kubelet[167]: I0414 12:19:20.692752     167 server.go:198] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
Apr 14 12:19:20 clusterfuck-worker3 kubelet[167]: Flag --pod-infra-container-image has been deprecated, will be removed in 1.27. Image garbage collector will get sandbox image information from CRI.
Apr 14 12:19:20 clusterfuck-worker3 kubelet[167]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:20 clusterfuck-worker3 kubelet[167]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:20 clusterfuck-worker3 kubelet[167]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.217320     167 server.go:412] "Kubelet version" kubeletVersion="v1.26.3"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.217376     167 server.go:414] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.217619     167 server.go:836] "Client rotation is on, will bootstrap in background"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.222774     167 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/ca.crt"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: W0414 12:19:21.233455     167 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.260673     167 container_manager_linux.go:267] "Container manager verified user specified cgroup-root exists" cgroupRoot=[kubelet]
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.260760     167 container_manager_linux.go:272] "Creating Container Manager object based on Node Config" nodeConfig={RuntimeCgroupsName: SystemCgroupsName: KubeletCgroupsName: KubeletOOMScoreAdj:-999 ContainerRuntime: CgroupsPerQOS:true CgroupRoot:/kubelet CgroupDriver:systemd KubeletRootDir:/var/lib/kubelet ProtectKernelDefaults:false NodeAllocatableConfig:{KubeReservedCgroupName: SystemReservedCgroupName: ReservedSystemCPUs: EnforceNodeAllocatable:map[pods:{}] KubeReserved:map[] SystemReserved:map[] HardEvictionThresholds:[]} QOSReserved:map[] CPUManagerPolicy:none CPUManagerPolicyOptions:map[] ExperimentalTopologyManagerScope:container CPUManagerReconcilePeriod:10s ExperimentalMemoryManagerPolicy:None ExperimentalMemoryManagerReservedMemory:[] ExperimentalPodPidsLimit:-1 EnforceCPULimits:true CPUCFSQuotaPeriod:100ms ExperimentalTopologyManagerPolicy:none ExperimentalTopologyManagerPolicyOptions:map[]}
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.260781     167 topology_manager.go:134] "Creating topology manager with policy per scope" topologyPolicyName="none" topologyScopeName="container"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.260792     167 container_manager_linux.go:308] "Creating device plugin manager"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.260874     167 state_mem.go:36] "Initialized new in-memory state store"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.273303     167 kubelet.go:398] "Attempting to sync node with API server"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.273973     167 kubelet.go:286] "Adding static pod path" path="/etc/kubernetes/manifests"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.274128     167 kubelet.go:297] "Adding apiserver pod source"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.274183     167 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.280896     167 kuberuntime_manager.go:244] "Container runtime initialized" containerRuntime="containerd" version="v1.6.19-46-g941215f49" apiVersion="v1"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: W0414 12:19:21.281250     167 probe.go:268] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.282139     167 server.go:1186] "Started kubelet"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.283282     167 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.287215     167 server.go:161] "Starting to listen" address="0.0.0.0" port=10250
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.302408     167 server.go:451] "Adding debug handlers to kubelet server"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.310564     167 volume_manager.go:293] "Starting Kubelet Volume Manager"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.311100     167 desired_state_of_world_populator.go:151] "Desired state populator starts to run"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.356648     167 cpu_manager.go:214] "Starting CPU manager" policy="none"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.356665     167 cpu_manager.go:215] "Reconciling" reconcilePeriod="10s"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.356679     167 state_mem.go:36] "Initialized new in-memory state store"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.368268     167 policy_none.go:49] "None policy: Start"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.371095     167 memory_manager.go:169] "Starting memorymanager" policy="None"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: I0414 12:19:21.371124     167 state_mem.go:35] "Initializing new in-memory state store"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: E0414 12:19:21.395005     167 controller.go:146] failed to ensure lease exists, will retry in 200ms, error: leases.coordination.k8s.io "clusterfuck-worker3" is forbidden: User "system:anonymous" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-node-lease"
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: W0414 12:19:21.395173     167 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: E0414 12:19:21.395246     167 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: W0414 12:19:21.395327     167 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: nodes "clusterfuck-worker3" is forbidden: User "system:anonymous" cannot list resource "nodes" in API group "" at the cluster scope
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: E0414 12:19:21.395382     167 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: nodes "clusterfuck-worker3" is forbidden: User "system:anonymous" cannot list resource "nodes" in API group "" at the cluster scope
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: E0414 12:19:21.395452     167 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc62f500d86c", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 21, 282082924, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 21, 282082924, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events is forbidden: User "system:anonymous" cannot create resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: W0414 12:19:21.395823     167 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: E0414 12:19:21.395847     167 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Apr 14 12:19:21 clusterfuck-worker3 kubelet[167]: E0414 12:19:21.450619     167 kubelet.go:1466] "Failed to start ContainerManager" err="failed to initialize top level QOS containers: root container [kubelet kubepods] doesn't exist"
Apr 14 12:19:21 clusterfuck-worker3 systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Apr 14 12:19:21 clusterfuck-worker3 systemd[1]: kubelet.service: Failed with result 'exit-code'.
Apr 14 12:19:22 clusterfuck-worker3 systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 1.
Apr 14 12:19:22 clusterfuck-worker3 systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Apr 14 12:19:22 clusterfuck-worker3 systemd[1]: Starting kubelet: The Kubernetes Node Agent...
Apr 14 12:19:22 clusterfuck-worker3 systemd[1]: Started kubelet: The Kubernetes Node Agent.
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: Flag --pod-infra-container-image has been deprecated, will be removed in 1.27. Image garbage collector will get sandbox image information from CRI.
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.702296     198 server.go:198] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: Flag --pod-infra-container-image has been deprecated, will be removed in 1.27. Image garbage collector will get sandbox image information from CRI.
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.714528     198 server.go:412] "Kubelet version" kubeletVersion="v1.26.3"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.714639     198 server.go:414] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.715102     198 server.go:836] "Client rotation is on, will bootstrap in background"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: E0414 12:19:22.715781     198 bootstrap.go:240] unable to read existing bootstrap client config from /etc/kubernetes/kubelet.conf: invalid configuration: [unable to read client-cert /var/lib/kubelet/pki/kubelet-client-current.pem for default-auth due to open /var/lib/kubelet/pki/kubelet-client-current.pem: no such file or directory, unable to read client-key /var/lib/kubelet/pki/kubelet-client-current.pem for default-auth due to open /var/lib/kubelet/pki/kubelet-client-current.pem: no such file or directory]
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.719084     198 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/ca.crt"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: W0414 12:19:22.723024     198 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.735237     198 container_manager_linux.go:267] "Container manager verified user specified cgroup-root exists" cgroupRoot=[kubelet]
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.735394     198 container_manager_linux.go:272] "Creating Container Manager object based on Node Config" nodeConfig={RuntimeCgroupsName: SystemCgroupsName: KubeletCgroupsName: KubeletOOMScoreAdj:-999 ContainerRuntime: CgroupsPerQOS:true CgroupRoot:/kubelet CgroupDriver:systemd KubeletRootDir:/var/lib/kubelet ProtectKernelDefaults:false NodeAllocatableConfig:{KubeReservedCgroupName: SystemReservedCgroupName: ReservedSystemCPUs: EnforceNodeAllocatable:map[pods:{}] KubeReserved:map[] SystemReserved:map[] HardEvictionThresholds:[]} QOSReserved:map[] CPUManagerPolicy:none CPUManagerPolicyOptions:map[] ExperimentalTopologyManagerScope:container CPUManagerReconcilePeriod:10s ExperimentalMemoryManagerPolicy:None ExperimentalMemoryManagerReservedMemory:[] ExperimentalPodPidsLimit:-1 EnforceCPULimits:true CPUCFSQuotaPeriod:100ms ExperimentalTopologyManagerPolicy:none ExperimentalTopologyManagerPolicyOptions:map[]}
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.735498     198 topology_manager.go:134] "Creating topology manager with policy per scope" topologyPolicyName="none" topologyScopeName="container"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.735555     198 container_manager_linux.go:308] "Creating device plugin manager"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.735620     198 state_mem.go:36] "Initialized new in-memory state store"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.741496     198 kubelet.go:398] "Attempting to sync node with API server"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.741605     198 kubelet.go:286] "Adding static pod path" path="/etc/kubernetes/manifests"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.741672     198 kubelet.go:297] "Adding apiserver pod source"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.741773     198 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.745185     198 kuberuntime_manager.go:244] "Container runtime initialized" containerRuntime="containerd" version="v1.6.19-46-g941215f49" apiVersion="v1"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.748180     198 server.go:1186] "Started kubelet"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.749808     198 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.764971     198 server.go:161] "Starting to listen" address="0.0.0.0" port=10250
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.765746     198 server.go:451] "Adding debug handlers to kubelet server"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.766893     198 volume_manager.go:293] "Starting Kubelet Volume Manager"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.766904     198 desired_state_of_world_populator.go:151] "Desired state populator starts to run"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.825306     198 cpu_manager.go:214] "Starting CPU manager" policy="none"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.825355     198 cpu_manager.go:215] "Reconciling" reconcilePeriod="10s"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.825372     198 state_mem.go:36] "Initialized new in-memory state store"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.825606     198 state_mem.go:88] "Updated default CPUSet" cpuSet=""
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.825652     198 state_mem.go:96] "Updated CPUSet assignments" assignments=map[]
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.825664     198 policy_none.go:49] "None policy: Start"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.827907     198 memory_manager.go:169] "Starting memorymanager" policy="None"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.827933     198 state_mem.go:35] "Initializing new in-memory state store"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.828235     198 state_mem.go:75] "Updated machine memory state"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: W0414 12:19:22.875128     198 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: E0414 12:19:22.875228     198 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: E0414 12:19:22.875394     198 controller.go:146] failed to ensure lease exists, will retry in 200ms, error: leases.coordination.k8s.io "clusterfuck-worker3" is forbidden: User "system:anonymous" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-node-lease"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: W0414 12:19:22.875663     198 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: nodes "clusterfuck-worker3" is forbidden: User "system:anonymous" cannot list resource "nodes" in API group "" at the cluster scope
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: E0414 12:19:22.875683     198 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: nodes "clusterfuck-worker3" is forbidden: User "system:anonymous" cannot list resource "nodes" in API group "" at the cluster scope
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: E0414 12:19:22.876510     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc634c637114", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 748162324, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 748162324, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events is forbidden: User "system:anonymous" cannot create resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: W0414 12:19:22.880709     198 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: E0414 12:19:22.884035     198 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.884417     198 manager.go:455] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.884699     198 plugin_manager.go:118] "Starting Kubelet Plugin Manager"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: I0414 12:19:22.890013     198 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-worker3"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: E0414 12:19:22.894518     198 eviction_manager.go:261] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"clusterfuck-worker3\" not found"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: E0414 12:19:22.897170     198 kubelet_node_status.go:92] "Unable to register node with API server" err="nodes is forbidden: User \"system:anonymous\" cannot create resource \"nodes\" in API group \"\" at the cluster scope" node="clusterfuck-worker3"
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: E0414 12:19:22.897169     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d449ee", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node clusterfuck-worker3 status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822666734, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822666734, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events is forbidden: User "system:anonymous" cannot create resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: E0414 12:19:22.901227     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d46dd4", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node clusterfuck-worker3 status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822675924, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822675924, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events is forbidden: User "system:anonymous" cannot create resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: E0414 12:19:22.915851     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d4780d", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node clusterfuck-worker3 status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822678541, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822678541, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events is forbidden: User "system:anonymous" cannot create resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: E0414 12:19:22.917994     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d449ee", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node clusterfuck-worker3 status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822666734, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 889980998, time.Local), Count:2, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "clusterfuck-worker3.1755cc6350d449ee" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: E0414 12:19:22.926597     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d46dd4", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node clusterfuck-worker3 status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822675924, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 889985382, time.Local), Count:2, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "clusterfuck-worker3.1755cc6350d46dd4" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: E0414 12:19:22.963669     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d4780d", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node clusterfuck-worker3 status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822678541, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 889987274, time.Local), Count:2, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "clusterfuck-worker3.1755cc6350d4780d" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:22 clusterfuck-worker3 kubelet[198]: E0414 12:19:22.969907     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6355224573", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeAllocatableEnforced", Message:"Updated Node Allocatable limit across pods", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 894886259, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 894886259, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events is forbidden: User "system:anonymous" cannot create resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:23 clusterfuck-worker3 kubelet[198]: I0414 12:19:23.015369     198 kubelet_network_linux.go:63] "Initialized iptables rules." protocol=IPv4
Apr 14 12:19:23 clusterfuck-worker3 kubelet[198]: I0414 12:19:23.073513     198 kubelet_network_linux.go:63] "Initialized iptables rules." protocol=IPv6
Apr 14 12:19:23 clusterfuck-worker3 kubelet[198]: I0414 12:19:23.074090     198 status_manager.go:176] "Starting to sync pod status with apiserver"
Apr 14 12:19:23 clusterfuck-worker3 kubelet[198]: I0414 12:19:23.074217     198 kubelet.go:2113] "Starting kubelet main sync loop"
Apr 14 12:19:23 clusterfuck-worker3 kubelet[198]: E0414 12:19:23.074436     198 kubelet.go:2137] "Skipping pod synchronization" err="PLEG is not healthy: pleg has yet to be successful"
Apr 14 12:19:23 clusterfuck-worker3 kubelet[198]: E0414 12:19:23.080646     198 controller.go:146] failed to ensure lease exists, will retry in 400ms, error: leases.coordination.k8s.io "clusterfuck-worker3" is forbidden: User "system:anonymous" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-node-lease"
Apr 14 12:19:23 clusterfuck-worker3 kubelet[198]: W0414 12:19:23.080908     198 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.RuntimeClass: runtimeclasses.node.k8s.io is forbidden: User "system:anonymous" cannot list resource "runtimeclasses" in API group "node.k8s.io" at the cluster scope
Apr 14 12:19:23 clusterfuck-worker3 kubelet[198]: E0414 12:19:23.080989     198 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: runtimeclasses.node.k8s.io is forbidden: User "system:anonymous" cannot list resource "runtimeclasses" in API group "node.k8s.io" at the cluster scope
Apr 14 12:19:23 clusterfuck-worker3 kubelet[198]: I0414 12:19:23.099103     198 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-worker3"
Apr 14 12:19:23 clusterfuck-worker3 kubelet[198]: E0414 12:19:23.104813     198 kubelet_node_status.go:92] "Unable to register node with API server" err="nodes is forbidden: User \"system:anonymous\" cannot create resource \"nodes\" in API group \"\" at the cluster scope" node="clusterfuck-worker3"
Apr 14 12:19:23 clusterfuck-worker3 kubelet[198]: E0414 12:19:23.105752     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d449ee", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node clusterfuck-worker3 status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822666734, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 23, 99074514, time.Local), Count:3, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "clusterfuck-worker3.1755cc6350d449ee" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:23 clusterfuck-worker3 kubelet[198]: E0414 12:19:23.108761     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d46dd4", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node clusterfuck-worker3 status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822675924, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 23, 99078261, time.Local), Count:3, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "clusterfuck-worker3.1755cc6350d46dd4" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:23 clusterfuck-worker3 kubelet[198]: E0414 12:19:23.111393     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d4780d", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node clusterfuck-worker3 status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822678541, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 23, 99080350, time.Local), Count:3, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "clusterfuck-worker3.1755cc6350d4780d" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:23 clusterfuck-worker3 kubelet[198]: E0414 12:19:23.482661     198 controller.go:146] failed to ensure lease exists, will retry in 800ms, error: leases.coordination.k8s.io "clusterfuck-worker3" is forbidden: User "system:anonymous" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-node-lease"
Apr 14 12:19:23 clusterfuck-worker3 kubelet[198]: I0414 12:19:23.506373     198 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-worker3"
Apr 14 12:19:23 clusterfuck-worker3 kubelet[198]: E0414 12:19:23.509157     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d449ee", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node clusterfuck-worker3 status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822666734, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 23, 506344779, time.Local), Count:4, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "clusterfuck-worker3.1755cc6350d449ee" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:23 clusterfuck-worker3 kubelet[198]: E0414 12:19:23.510464     198 kubelet_node_status.go:92] "Unable to register node with API server" err="nodes is forbidden: User \"system:anonymous\" cannot create resource \"nodes\" in API group \"\" at the cluster scope" node="clusterfuck-worker3"
Apr 14 12:19:23 clusterfuck-worker3 kubelet[198]: E0414 12:19:23.511416     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d46dd4", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node clusterfuck-worker3 status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822675924, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 23, 506348929, time.Local), Count:4, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "clusterfuck-worker3.1755cc6350d46dd4" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:23 clusterfuck-worker3 kubelet[198]: E0414 12:19:23.553051     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d4780d", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node clusterfuck-worker3 status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822678541, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 23, 506350819, time.Local), Count:4, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "clusterfuck-worker3.1755cc6350d4780d" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:24 clusterfuck-worker3 kubelet[198]: W0414 12:19:24.185947     198 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.RuntimeClass: runtimeclasses.node.k8s.io is forbidden: User "system:anonymous" cannot list resource "runtimeclasses" in API group "node.k8s.io" at the cluster scope
Apr 14 12:19:24 clusterfuck-worker3 kubelet[198]: E0414 12:19:24.185989     198 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: runtimeclasses.node.k8s.io is forbidden: User "system:anonymous" cannot list resource "runtimeclasses" in API group "node.k8s.io" at the cluster scope
Apr 14 12:19:24 clusterfuck-worker3 kubelet[198]: W0414 12:19:24.209253     198 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: nodes "clusterfuck-worker3" is forbidden: User "system:anonymous" cannot list resource "nodes" in API group "" at the cluster scope
Apr 14 12:19:24 clusterfuck-worker3 kubelet[198]: E0414 12:19:24.209312     198 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: nodes "clusterfuck-worker3" is forbidden: User "system:anonymous" cannot list resource "nodes" in API group "" at the cluster scope
Apr 14 12:19:24 clusterfuck-worker3 kubelet[198]: E0414 12:19:24.284960     198 controller.go:146] failed to ensure lease exists, will retry in 1.6s, error: leases.coordination.k8s.io "clusterfuck-worker3" is forbidden: User "system:anonymous" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-node-lease"
Apr 14 12:19:24 clusterfuck-worker3 kubelet[198]: W0414 12:19:24.311620     198 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Apr 14 12:19:24 clusterfuck-worker3 kubelet[198]: E0414 12:19:24.311754     198 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Apr 14 12:19:24 clusterfuck-worker3 kubelet[198]: I0414 12:19:24.311728     198 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-worker3"
Apr 14 12:19:24 clusterfuck-worker3 kubelet[198]: E0414 12:19:24.313041     198 kubelet_node_status.go:92] "Unable to register node with API server" err="nodes is forbidden: User \"system:anonymous\" cannot create resource \"nodes\" in API group \"\" at the cluster scope" node="clusterfuck-worker3"
Apr 14 12:19:24 clusterfuck-worker3 kubelet[198]: E0414 12:19:24.314187     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d449ee", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node clusterfuck-worker3 status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822666734, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 24, 311695922, time.Local), Count:5, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "clusterfuck-worker3.1755cc6350d449ee" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:24 clusterfuck-worker3 kubelet[198]: E0414 12:19:24.317254     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d46dd4", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node clusterfuck-worker3 status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822675924, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 24, 311706194, time.Local), Count:5, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "clusterfuck-worker3.1755cc6350d46dd4" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:24 clusterfuck-worker3 kubelet[198]: E0414 12:19:24.318760     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d4780d", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node clusterfuck-worker3 status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822678541, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 24, 311708210, time.Local), Count:5, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "clusterfuck-worker3.1755cc6350d4780d" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:24 clusterfuck-worker3 kubelet[198]: W0414 12:19:24.436589     198 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Apr 14 12:19:24 clusterfuck-worker3 kubelet[198]: E0414 12:19:24.436648     198 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Apr 14 12:19:25 clusterfuck-worker3 kubelet[198]: E0414 12:19:25.888105     198 controller.go:146] failed to ensure lease exists, will retry in 3.2s, error: leases.coordination.k8s.io "clusterfuck-worker3" is forbidden: User "system:anonymous" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-node-lease"
Apr 14 12:19:25 clusterfuck-worker3 kubelet[198]: I0414 12:19:25.914593     198 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-worker3"
Apr 14 12:19:25 clusterfuck-worker3 kubelet[198]: E0414 12:19:25.916223     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d449ee", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node clusterfuck-worker3 status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822666734, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 25, 914560094, time.Local), Count:6, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "clusterfuck-worker3.1755cc6350d449ee" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:25 clusterfuck-worker3 kubelet[198]: E0414 12:19:25.916980     198 kubelet_node_status.go:92] "Unable to register node with API server" err="nodes is forbidden: User \"system:anonymous\" cannot create resource \"nodes\" in API group \"\" at the cluster scope" node="clusterfuck-worker3"
Apr 14 12:19:25 clusterfuck-worker3 kubelet[198]: E0414 12:19:25.917229     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d46dd4", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node clusterfuck-worker3 status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822675924, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 25, 914563666, time.Local), Count:6, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "clusterfuck-worker3.1755cc6350d46dd4" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:25 clusterfuck-worker3 kubelet[198]: E0414 12:19:25.920495     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d4780d", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node clusterfuck-worker3 status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822678541, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 25, 914569718, time.Local), Count:6, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "clusterfuck-worker3.1755cc6350d4780d" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:26 clusterfuck-worker3 kubelet[198]: W0414 12:19:26.221265     198 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Apr 14 12:19:26 clusterfuck-worker3 kubelet[198]: E0414 12:19:26.221326     198 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Apr 14 12:19:26 clusterfuck-worker3 kubelet[198]: W0414 12:19:26.222317     198 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Apr 14 12:19:26 clusterfuck-worker3 kubelet[198]: E0414 12:19:26.222371     198 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Apr 14 12:19:26 clusterfuck-worker3 kubelet[198]: W0414 12:19:26.458880     198 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.RuntimeClass: runtimeclasses.node.k8s.io is forbidden: User "system:anonymous" cannot list resource "runtimeclasses" in API group "node.k8s.io" at the cluster scope
Apr 14 12:19:26 clusterfuck-worker3 kubelet[198]: E0414 12:19:26.459009     198 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: runtimeclasses.node.k8s.io is forbidden: User "system:anonymous" cannot list resource "runtimeclasses" in API group "node.k8s.io" at the cluster scope
Apr 14 12:19:27 clusterfuck-worker3 kubelet[198]: W0414 12:19:27.171521     198 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: nodes "clusterfuck-worker3" is forbidden: User "system:anonymous" cannot list resource "nodes" in API group "" at the cluster scope
Apr 14 12:19:27 clusterfuck-worker3 kubelet[198]: E0414 12:19:27.171586     198 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: nodes "clusterfuck-worker3" is forbidden: User "system:anonymous" cannot list resource "nodes" in API group "" at the cluster scope
Apr 14 12:19:29 clusterfuck-worker3 kubelet[198]: E0414 12:19:29.090541     198 controller.go:146] failed to ensure lease exists, will retry in 6.4s, error: leases.coordination.k8s.io "clusterfuck-worker3" is forbidden: User "system:anonymous" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-node-lease"
Apr 14 12:19:29 clusterfuck-worker3 kubelet[198]: I0414 12:19:29.118656     198 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-worker3"
Apr 14 12:19:29 clusterfuck-worker3 kubelet[198]: E0414 12:19:29.120270     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d449ee", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node clusterfuck-worker3 status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822666734, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 29, 118610289, time.Local), Count:7, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "clusterfuck-worker3.1755cc6350d449ee" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:29 clusterfuck-worker3 kubelet[198]: E0414 12:19:29.120573     198 kubelet_node_status.go:92] "Unable to register node with API server" err="nodes is forbidden: User \"system:anonymous\" cannot create resource \"nodes\" in API group \"\" at the cluster scope" node="clusterfuck-worker3"
Apr 14 12:19:29 clusterfuck-worker3 kubelet[198]: E0414 12:19:29.121096     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d46dd4", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node clusterfuck-worker3 status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822675924, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 29, 118614378, time.Local), Count:7, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "clusterfuck-worker3.1755cc6350d46dd4" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:29 clusterfuck-worker3 kubelet[198]: E0414 12:19:29.123791     198 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-worker3.1755cc6350d4780d", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-worker3", UID:"clusterfuck-worker3", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node clusterfuck-worker3 status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-worker3"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 19, 22, 822678541, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 19, 29, 118632854, time.Local), Count:7, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "clusterfuck-worker3.1755cc6350d4780d" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 12:19:30 clusterfuck-worker3 kubelet[198]: W0414 12:19:30.093466     198 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Apr 14 12:19:30 clusterfuck-worker3 kubelet[198]: E0414 12:19:30.093496     198 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Apr 14 12:19:30 clusterfuck-worker3 kubelet[198]: W0414 12:19:30.693528     198 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.RuntimeClass: runtimeclasses.node.k8s.io is forbidden: User "system:anonymous" cannot list resource "runtimeclasses" in API group "node.k8s.io" at the cluster scope
Apr 14 12:19:30 clusterfuck-worker3 kubelet[198]: E0414 12:19:30.693574     198 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: runtimeclasses.node.k8s.io is forbidden: User "system:anonymous" cannot list resource "runtimeclasses" in API group "node.k8s.io" at the cluster scope
Apr 14 12:19:31 clusterfuck-worker3 kubelet[198]: W0414 12:19:31.785342     198 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Apr 14 12:19:31 clusterfuck-worker3 kubelet[198]: E0414 12:19:31.785837     198 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Apr 14 12:19:32 clusterfuck-worker3 kubelet[198]: W0414 12:19:32.093131     198 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: nodes "clusterfuck-worker3" is forbidden: User "system:anonymous" cannot list resource "nodes" in API group "" at the cluster scope
Apr 14 12:19:32 clusterfuck-worker3 kubelet[198]: E0414 12:19:32.093197     198 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: nodes "clusterfuck-worker3" is forbidden: User "system:anonymous" cannot list resource "nodes" in API group "" at the cluster scope
Apr 14 12:19:32 clusterfuck-worker3 kubelet[198]: I0414 12:19:32.734483     198 transport.go:135] "Certificate rotation detected, shutting down client connections to start using new credentials"
Apr 14 12:19:32 clusterfuck-worker3 kubelet[198]: E0414 12:19:32.894850     198 eviction_manager.go:261] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"clusterfuck-worker3\" not found"
Apr 14 12:19:33 clusterfuck-worker3 kubelet[198]: E0414 12:19:33.221551     198 csi_plugin.go:295] Failed to initialize CSINode: error updating CSINode annotation: timed out waiting for the condition; caused by: nodes "clusterfuck-worker3" not found
Apr 14 12:19:34 clusterfuck-worker3 kubelet[198]: E0414 12:19:34.281187     198 csi_plugin.go:295] Failed to initialize CSINode: error updating CSINode annotation: timed out waiting for the condition; caused by: nodes "clusterfuck-worker3" not found
Apr 14 12:19:35 clusterfuck-worker3 kubelet[198]: E0414 12:19:35.495592     198 nodelease.go:49] "Failed to get node when trying to set owner ref to the node lease" err="nodes \"clusterfuck-worker3\" not found" node="clusterfuck-worker3"
Apr 14 12:19:35 clusterfuck-worker3 kubelet[198]: I0414 12:19:35.521871     198 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-worker3"
Apr 14 12:19:35 clusterfuck-worker3 kubelet[198]: I0414 12:19:35.684245     198 kubelet_node_status.go:73] "Successfully registered node" node="clusterfuck-worker3"
Apr 14 12:19:35 clusterfuck-worker3 kubelet[198]: E0414 12:19:35.691691     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:35 clusterfuck-worker3 kubelet[198]: E0414 12:19:35.793147     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:35 clusterfuck-worker3 kubelet[198]: E0414 12:19:35.893817     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:35 clusterfuck-worker3 kubelet[198]: E0414 12:19:35.994243     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:36 clusterfuck-worker3 kubelet[198]: E0414 12:19:36.094924     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:36 clusterfuck-worker3 kubelet[198]: E0414 12:19:36.196212     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:36 clusterfuck-worker3 kubelet[198]: E0414 12:19:36.296716     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:36 clusterfuck-worker3 kubelet[198]: E0414 12:19:36.398006     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:36 clusterfuck-worker3 kubelet[198]: E0414 12:19:36.499120     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:36 clusterfuck-worker3 kubelet[198]: E0414 12:19:36.599938     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:36 clusterfuck-worker3 kubelet[198]: E0414 12:19:36.700888     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:36 clusterfuck-worker3 kubelet[198]: E0414 12:19:36.801808     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:36 clusterfuck-worker3 kubelet[198]: E0414 12:19:36.902068     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:37 clusterfuck-worker3 kubelet[198]: E0414 12:19:37.003123     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:37 clusterfuck-worker3 kubelet[198]: E0414 12:19:37.103355     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:37 clusterfuck-worker3 kubelet[198]: E0414 12:19:37.204060     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:37 clusterfuck-worker3 kubelet[198]: E0414 12:19:37.305350     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:37 clusterfuck-worker3 kubelet[198]: E0414 12:19:37.406337     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:37 clusterfuck-worker3 kubelet[198]: E0414 12:19:37.506714     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:37 clusterfuck-worker3 kubelet[198]: E0414 12:19:37.607825     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:37 clusterfuck-worker3 kubelet[198]: E0414 12:19:37.708319     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:37 clusterfuck-worker3 kubelet[198]: E0414 12:19:37.809302     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:37 clusterfuck-worker3 kubelet[198]: E0414 12:19:37.911110     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:38 clusterfuck-worker3 kubelet[198]: E0414 12:19:38.011989     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:38 clusterfuck-worker3 kubelet[198]: E0414 12:19:38.112596     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:38 clusterfuck-worker3 kubelet[198]: E0414 12:19:38.213756     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:38 clusterfuck-worker3 kubelet[198]: E0414 12:19:38.314588     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:38 clusterfuck-worker3 kubelet[198]: E0414 12:19:38.415773     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:38 clusterfuck-worker3 kubelet[198]: E0414 12:19:38.516475     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:38 clusterfuck-worker3 kubelet[198]: E0414 12:19:38.616960     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:38 clusterfuck-worker3 kubelet[198]: E0414 12:19:38.718265     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:38 clusterfuck-worker3 kubelet[198]: E0414 12:19:38.818742     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:38 clusterfuck-worker3 kubelet[198]: E0414 12:19:38.919441     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:39 clusterfuck-worker3 kubelet[198]: E0414 12:19:39.020597     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:39 clusterfuck-worker3 kubelet[198]: E0414 12:19:39.121754     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:39 clusterfuck-worker3 kubelet[198]: E0414 12:19:39.222789     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:39 clusterfuck-worker3 kubelet[198]: E0414 12:19:39.323838     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:39 clusterfuck-worker3 kubelet[198]: E0414 12:19:39.424794     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:39 clusterfuck-worker3 kubelet[198]: E0414 12:19:39.525755     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:39 clusterfuck-worker3 kubelet[198]: E0414 12:19:39.626749     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:39 clusterfuck-worker3 kubelet[198]: E0414 12:19:39.728045     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:39 clusterfuck-worker3 kubelet[198]: E0414 12:19:39.829263     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:39 clusterfuck-worker3 kubelet[198]: E0414 12:19:39.929512     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:40 clusterfuck-worker3 kubelet[198]: E0414 12:19:40.030555     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:40 clusterfuck-worker3 kubelet[198]: E0414 12:19:40.131877     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:40 clusterfuck-worker3 kubelet[198]: E0414 12:19:40.233378     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:40 clusterfuck-worker3 kubelet[198]: E0414 12:19:40.334803     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:40 clusterfuck-worker3 kubelet[198]: E0414 12:19:40.435336     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:40 clusterfuck-worker3 kubelet[198]: E0414 12:19:40.535516     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:40 clusterfuck-worker3 kubelet[198]: E0414 12:19:40.636067     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:40 clusterfuck-worker3 kubelet[198]: E0414 12:19:40.736632     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:40 clusterfuck-worker3 kubelet[198]: E0414 12:19:40.836980     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:40 clusterfuck-worker3 kubelet[198]: E0414 12:19:40.938110     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:41 clusterfuck-worker3 kubelet[198]: E0414 12:19:41.039275     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:41 clusterfuck-worker3 kubelet[198]: E0414 12:19:41.140363     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:41 clusterfuck-worker3 kubelet[198]: E0414 12:19:41.242774     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:41 clusterfuck-worker3 kubelet[198]: E0414 12:19:41.343566     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:41 clusterfuck-worker3 kubelet[198]: E0414 12:19:41.444089     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:41 clusterfuck-worker3 kubelet[198]: E0414 12:19:41.545111     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:41 clusterfuck-worker3 kubelet[198]: E0414 12:19:41.645942     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:41 clusterfuck-worker3 kubelet[198]: E0414 12:19:41.746143     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:41 clusterfuck-worker3 kubelet[198]: E0414 12:19:41.847183     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:41 clusterfuck-worker3 kubelet[198]: E0414 12:19:41.948238     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:42 clusterfuck-worker3 kubelet[198]: E0414 12:19:42.048756     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:42 clusterfuck-worker3 kubelet[198]: E0414 12:19:42.152357     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:42 clusterfuck-worker3 kubelet[198]: E0414 12:19:42.254964     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:42 clusterfuck-worker3 kubelet[198]: E0414 12:19:42.355541     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:42 clusterfuck-worker3 kubelet[198]: E0414 12:19:42.456465     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:42 clusterfuck-worker3 kubelet[198]: E0414 12:19:42.557415     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:42 clusterfuck-worker3 kubelet[198]: E0414 12:19:42.658187     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:42 clusterfuck-worker3 kubelet[198]: E0414 12:19:42.759401     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:42 clusterfuck-worker3 kubelet[198]: E0414 12:19:42.860441     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:42 clusterfuck-worker3 kubelet[198]: E0414 12:19:42.896221     198 eviction_manager.go:261] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"clusterfuck-worker3\" not found"
Apr 14 12:19:42 clusterfuck-worker3 kubelet[198]: E0414 12:19:42.961376     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:43 clusterfuck-worker3 kubelet[198]: E0414 12:19:43.061599     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:43 clusterfuck-worker3 kubelet[198]: E0414 12:19:43.162786     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:43 clusterfuck-worker3 kubelet[198]: E0414 12:19:43.263843     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:43 clusterfuck-worker3 kubelet[198]: E0414 12:19:43.364840     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:43 clusterfuck-worker3 kubelet[198]: E0414 12:19:43.464980     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:43 clusterfuck-worker3 kubelet[198]: E0414 12:19:43.565670     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:43 clusterfuck-worker3 kubelet[198]: E0414 12:19:43.665902     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:43 clusterfuck-worker3 kubelet[198]: E0414 12:19:43.766822     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:43 clusterfuck-worker3 kubelet[198]: E0414 12:19:43.867755     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:43 clusterfuck-worker3 kubelet[198]: E0414 12:19:43.968581     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:44 clusterfuck-worker3 kubelet[198]: E0414 12:19:44.068895     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:44 clusterfuck-worker3 kubelet[198]: E0414 12:19:44.169222     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:44 clusterfuck-worker3 kubelet[198]: E0414 12:19:44.269365     198 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"clusterfuck-worker3\" not found"
Apr 14 12:19:44 clusterfuck-worker3 kubelet[198]: I0414 12:19:44.371522     198 kuberuntime_manager.go:1114] "Updating runtime config through cri with podcidr" CIDR="10.244.2.0/24"
Apr 14 12:19:44 clusterfuck-worker3 kubelet[198]: I0414 12:19:44.372490     198 kubelet_network.go:61] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.244.2.0/24"
Apr 14 12:19:44 clusterfuck-worker3 kubelet[198]: I0414 12:19:44.763206     198 apiserver.go:52] "Watching apiserver"
Apr 14 12:19:44 clusterfuck-worker3 kubelet[198]: I0414 12:19:44.765286     198 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:19:44 clusterfuck-worker3 kubelet[198]: I0414 12:19:44.765383     198 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:19:44 clusterfuck-worker3 kubelet[198]: I0414 12:19:44.779145     198 desired_state_of_world_populator.go:159] "Finished populating initial desired state of world"
Apr 14 12:19:44 clusterfuck-worker3 kubelet[198]: I0414 12:19:44.866288     198 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/f10c5303-69d9-4894-ba0f-18a022d5c192-kube-proxy\") pod \"kube-proxy-cvv2r\" (UID: \"f10c5303-69d9-4894-ba0f-18a022d5c192\") " pod="kube-system/kube-proxy-cvv2r"
Apr 14 12:19:44 clusterfuck-worker3 kubelet[198]: I0414 12:19:44.866362     198 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/f10c5303-69d9-4894-ba0f-18a022d5c192-xtables-lock\") pod \"kube-proxy-cvv2r\" (UID: \"f10c5303-69d9-4894-ba0f-18a022d5c192\") " pod="kube-system/kube-proxy-cvv2r"
Apr 14 12:19:44 clusterfuck-worker3 kubelet[198]: I0414 12:19:44.866394     198 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/f10c5303-69d9-4894-ba0f-18a022d5c192-lib-modules\") pod \"kube-proxy-cvv2r\" (UID: \"f10c5303-69d9-4894-ba0f-18a022d5c192\") " pod="kube-system/kube-proxy-cvv2r"
Apr 14 12:19:44 clusterfuck-worker3 kubelet[198]: I0414 12:19:44.866413     198 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-4jzr5\" (UniqueName: \"kubernetes.io/projected/f10c5303-69d9-4894-ba0f-18a022d5c192-kube-api-access-4jzr5\") pod \"kube-proxy-cvv2r\" (UID: \"f10c5303-69d9-4894-ba0f-18a022d5c192\") " pod="kube-system/kube-proxy-cvv2r"
Apr 14 12:19:44 clusterfuck-worker3 kubelet[198]: I0414 12:19:44.866431     198 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cni-cfg\" (UniqueName: \"kubernetes.io/host-path/af9fa247-e423-4011-8374-4130976b71df-cni-cfg\") pod \"kindnet-grscj\" (UID: \"af9fa247-e423-4011-8374-4130976b71df\") " pod="kube-system/kindnet-grscj"
Apr 14 12:19:44 clusterfuck-worker3 kubelet[198]: I0414 12:19:44.866449     198 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/af9fa247-e423-4011-8374-4130976b71df-xtables-lock\") pod \"kindnet-grscj\" (UID: \"af9fa247-e423-4011-8374-4130976b71df\") " pod="kube-system/kindnet-grscj"
Apr 14 12:19:44 clusterfuck-worker3 kubelet[198]: I0414 12:19:44.866466     198 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/af9fa247-e423-4011-8374-4130976b71df-lib-modules\") pod \"kindnet-grscj\" (UID: \"af9fa247-e423-4011-8374-4130976b71df\") " pod="kube-system/kindnet-grscj"
Apr 14 12:19:44 clusterfuck-worker3 kubelet[198]: I0414 12:19:44.866550     198 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-crg5x\" (UniqueName: \"kubernetes.io/projected/af9fa247-e423-4011-8374-4130976b71df-kube-api-access-crg5x\") pod \"kindnet-grscj\" (UID: \"af9fa247-e423-4011-8374-4130976b71df\") " pod="kube-system/kindnet-grscj"
Apr 14 12:19:44 clusterfuck-worker3 kubelet[198]: I0414 12:19:44.866562     198 reconciler.go:41] "Reconciler: start to sync state"
Apr 14 12:19:46 clusterfuck-worker3 kubelet[198]: I0414 12:19:46.144765     198 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-proxy-cvv2r" podStartSLOduration=11.144510267 pod.CreationTimestamp="2023-04-14 12:19:35 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-04-14 12:19:46.144098327 +0000 UTC m=+23.552187821" watchObservedRunningTime="2023-04-14 12:19:46.144510267 +0000 UTC m=+23.552599769"
Apr 14 12:19:49 clusterfuck-worker3 kubelet[198]: I0414 12:19:49.016361     198 kubelet_node_status.go:493] "Fast updating node status as it just became ready"
Apr 14 12:24:22 clusterfuck-worker3 kubelet[198]: W0414 12:24:22.822454     198 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:29:22 clusterfuck-worker3 kubelet[198]: W0414 12:29:22.821410     198 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:34:22 clusterfuck-worker3 kubelet[198]: W0414 12:34:22.820293     198 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:39:22 clusterfuck-worker3 kubelet[198]: W0414 12:39:22.812248     198 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:44:22 clusterfuck-worker3 kubelet[198]: W0414 12:44:22.810736     198 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:49:22 clusterfuck-worker3 kubelet[198]: W0414 12:49:22.808148     198 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:54:22 clusterfuck-worker3 kubelet[198]: W0414 12:54:22.806214     198 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:59:22 clusterfuck-worker3 kubelet[198]: W0414 12:59:22.805166     198 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:04:22 clusterfuck-worker3 kubelet[198]: W0414 13:04:22.803873     198 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:09:22 clusterfuck-worker3 kubelet[198]: W0414 13:09:22.800979     198 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:14:22 clusterfuck-worker3 kubelet[198]: W0414 13:14:22.773609     198 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:19:22 clusterfuck-worker3 kubelet[198]: W0414 13:19:22.767215     198 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:24:22 clusterfuck-worker3 kubelet[198]: W0414 13:24:22.765068     198 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:29:22 clusterfuck-worker3 kubelet[198]: W0414 13:29:22.759663     198 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:34:22 clusterfuck-worker3 kubelet[198]: W0414 13:34:22.752367     198 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:39:22 clusterfuck-worker3 kubelet[198]: W0414 13:39:22.744644     198 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:44:22 clusterfuck-worker3 kubelet[198]: W0414 13:44:22.740486     198 sysinfo.go:203] Nodes topology is not available, providing CPU topology
