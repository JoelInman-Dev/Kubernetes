Apr 14 12:18:38 clusterfuck-control-plane systemd-journald[88]: Journal started
Apr 14 12:18:38 clusterfuck-control-plane systemd-journald[88]: Runtime Journal (/run/log/journal/d3d9c68fb5c544988130cdeb7ca1f5c5) is 8.0M, max 800.5M, 792.5M free.
Apr 14 12:18:38 clusterfuck-control-plane systemd-journald[88]: Runtime Journal (/run/log/journal/d3d9c68fb5c544988130cdeb7ca1f5c5) is 8.0M, max 800.5M, 792.5M free.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Starting Flush Journal to Persistent Storage...
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Finished Create System Users.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Finished Record System Boot/Shutdown in UTMP.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Finished Flush Journal to Persistent Storage.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Starting Create Static Device Nodes in /dev...
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Finished Create Static Device Nodes in /dev.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Reached target Preparation for Local File Systems.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Reached target Local File Systems.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Condition check resulted in Set Up Additional Binary Formats being skipped.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Condition check resulted in Store a System Token in an EFI Variable being skipped.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Condition check resulted in Commit a transient machine-id on disk being skipped.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Condition check resulted in Rule-based Manager for Device Events and Files being skipped.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Reached target System Initialization.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Started Daily Cleanup of Temporary Directories.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Reached target Basic System.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Reached target Timer Units.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Starting containerd container runtime...
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Condition check resulted in kubelet: The Kubernetes Node Agent being skipped.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Started containerd container runtime.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Reached target Multi-User System.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Reached target Graphical Interface.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Starting Record Runlevel Change in UTMP...
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: systemd-update-utmp-runlevel.service: Deactivated successfully.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Finished Record Runlevel Change in UTMP.
Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Startup finished in 2.049s.
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.055953070Z" level=info msg="starting containerd" revision=941215f4987b5d303cedbbf9f8c9c4fa99b903ff version=v1.6.19-46-g941215f49
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.143190720Z" level=info msg="loading plugin \"io.containerd.content.v1.content\"..." type=io.containerd.content.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.143465696Z" level=info msg="loading plugin \"io.containerd.snapshotter.v1.aufs\"..." type=io.containerd.snapshotter.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.161289138Z" level=info msg="skip loading plugin \"io.containerd.snapshotter.v1.aufs\"..." error="aufs is not supported (modprobe aufs failed: exit status 1 \"modprobe: FATAL: Module aufs not found in directory /lib/modules/5.15.49-linuxkit\\n\"): skip plugin" type=io.containerd.snapshotter.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.161965996Z" level=info msg="loading plugin \"io.containerd.snapshotter.v1.btrfs\"..." type=io.containerd.snapshotter.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.174429053Z" level=info msg="skip loading plugin \"io.containerd.snapshotter.v1.btrfs\"..." error="path /var/lib/containerd/io.containerd.snapshotter.v1.btrfs (ext4) must be a btrfs filesystem to be used with the btrfs snapshotter: skip plugin" type=io.containerd.snapshotter.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.175294726Z" level=info msg="loading plugin \"io.containerd.snapshotter.v1.devmapper\"..." type=io.containerd.snapshotter.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.179246453Z" level=warning msg="failed to load plugin io.containerd.snapshotter.v1.devmapper" error="devmapper not configured"
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.180901608Z" level=info msg="loading plugin \"io.containerd.snapshotter.v1.native\"..." type=io.containerd.snapshotter.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.181151400Z" level=info msg="loading plugin \"io.containerd.snapshotter.v1.overlayfs\"..." type=io.containerd.snapshotter.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.195081176Z" level=info msg="loading plugin \"io.containerd.snapshotter.v1.zfs\"..." type=io.containerd.snapshotter.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.212372559Z" level=info msg="skip loading plugin \"io.containerd.snapshotter.v1.zfs\"..." error="path /var/lib/containerd/io.containerd.snapshotter.v1.zfs must be a zfs filesystem to be used with the zfs snapshotter: skip plugin" type=io.containerd.snapshotter.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.212503565Z" level=info msg="loading plugin \"io.containerd.snapshotter.v1.fuse-overlayfs\"..." type=io.containerd.snapshotter.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.213133200Z" level=info msg="loading plugin \"io.containerd.metadata.v1.bolt\"..." type=io.containerd.metadata.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.213490044Z" level=warning msg="could not use snapshotter devmapper in metadata plugin" error="devmapper not configured"
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.213559494Z" level=info msg="metadata content store policy set" policy=shared
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.213763418Z" level=info msg="loading plugin \"io.containerd.differ.v1.walking\"..." type=io.containerd.differ.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.213940687Z" level=info msg="loading plugin \"io.containerd.event.v1.exchange\"..." type=io.containerd.event.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.214026631Z" level=info msg="loading plugin \"io.containerd.gc.v1.scheduler\"..." type=io.containerd.gc.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.214127896Z" level=info msg="loading plugin \"io.containerd.service.v1.introspection-service\"..." type=io.containerd.service.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.214235440Z" level=info msg="loading plugin \"io.containerd.service.v1.containers-service\"..." type=io.containerd.service.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.214295673Z" level=info msg="loading plugin \"io.containerd.service.v1.content-service\"..." type=io.containerd.service.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.214357003Z" level=info msg="loading plugin \"io.containerd.service.v1.diff-service\"..." type=io.containerd.service.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.214446358Z" level=info msg="loading plugin \"io.containerd.service.v1.images-service\"..." type=io.containerd.service.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.214510352Z" level=info msg="loading plugin \"io.containerd.service.v1.leases-service\"..." type=io.containerd.service.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.214710551Z" level=info msg="loading plugin \"io.containerd.service.v1.namespaces-service\"..." type=io.containerd.service.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.218015586Z" level=info msg="loading plugin \"io.containerd.service.v1.snapshots-service\"..." type=io.containerd.service.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.218867269Z" level=info msg="loading plugin \"io.containerd.runtime.v1.linux\"..." type=io.containerd.runtime.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.219029913Z" level=info msg="loading plugin \"io.containerd.runtime.v2.task\"..." type=io.containerd.runtime.v2
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.228042141Z" level=info msg="loading plugin \"io.containerd.monitor.v1.cgroups\"..." type=io.containerd.monitor.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.228427756Z" level=info msg="loading plugin \"io.containerd.service.v1.tasks-service\"..." type=io.containerd.service.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.228521403Z" level=info msg="loading plugin \"io.containerd.grpc.v1.introspection\"..." type=io.containerd.grpc.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.228591261Z" level=info msg="loading plugin \"io.containerd.internal.v1.restart\"..." type=io.containerd.internal.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.228689333Z" level=info msg="loading plugin \"io.containerd.grpc.v1.containers\"..." type=io.containerd.grpc.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.228753092Z" level=info msg="loading plugin \"io.containerd.grpc.v1.content\"..." type=io.containerd.grpc.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.228810345Z" level=info msg="loading plugin \"io.containerd.grpc.v1.diff\"..." type=io.containerd.grpc.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.228868142Z" level=info msg="loading plugin \"io.containerd.grpc.v1.events\"..." type=io.containerd.grpc.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.228920822Z" level=info msg="loading plugin \"io.containerd.grpc.v1.healthcheck\"..." type=io.containerd.grpc.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.228973456Z" level=info msg="loading plugin \"io.containerd.grpc.v1.images\"..." type=io.containerd.grpc.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.229025233Z" level=info msg="loading plugin \"io.containerd.grpc.v1.leases\"..." type=io.containerd.grpc.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.229087346Z" level=info msg="loading plugin \"io.containerd.grpc.v1.namespaces\"..." type=io.containerd.grpc.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.229143241Z" level=info msg="loading plugin \"io.containerd.internal.v1.opt\"..." type=io.containerd.internal.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.229248131Z" level=info msg="loading plugin \"io.containerd.grpc.v1.snapshots\"..." type=io.containerd.grpc.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.229309461Z" level=info msg="loading plugin \"io.containerd.grpc.v1.tasks\"..." type=io.containerd.grpc.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.229363261Z" level=info msg="loading plugin \"io.containerd.grpc.v1.version\"..." type=io.containerd.grpc.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.229637459Z" level=info msg="loading plugin \"io.containerd.tracing.processor.v1.otlp\"..." type=io.containerd.tracing.processor.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.229705507Z" level=info msg="skip loading plugin \"io.containerd.tracing.processor.v1.otlp\"..." error="no OpenTelemetry endpoint: skip plugin" type=io.containerd.tracing.processor.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.229757795Z" level=info msg="loading plugin \"io.containerd.internal.v1.tracing\"..." type=io.containerd.internal.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.229821536Z" level=error msg="failed to initialize a tracing processor \"otlp\"" error="no OpenTelemetry endpoint: skip plugin"
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.229902499Z" level=info msg="loading plugin \"io.containerd.grpc.v1.cri\"..." type=io.containerd.grpc.v1
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.230443404Z" level=info msg="Start cri plugin with config {PluginConfig:{ContainerdConfig:{Snapshotter:overlayfs DefaultRuntimeName:runc DefaultRuntime:{Type: Path: Engine: PodAnnotations:[] ContainerAnnotations:[] Root: Options:map[] PrivilegedWithoutHostDevices:false BaseRuntimeSpec: NetworkPluginConfDir: NetworkPluginMaxConfNum:0} UntrustedWorkloadRuntime:{Type: Path: Engine: PodAnnotations:[] ContainerAnnotations:[] Root: Options:map[] PrivilegedWithoutHostDevices:false BaseRuntimeSpec: NetworkPluginConfDir: NetworkPluginMaxConfNum:0} Runtimes:map[runc:{Type:io.containerd.runc.v2 Path: Engine: PodAnnotations:[] ContainerAnnotations:[] Root: Options:map[SystemdCgroup:true] PrivilegedWithoutHostDevices:false BaseRuntimeSpec:/etc/containerd/cri-base.json NetworkPluginConfDir: NetworkPluginMaxConfNum:0} test-handler:{Type:io.containerd.runc.v2 Path: Engine: PodAnnotations:[] ContainerAnnotations:[] Root: Options:map[SystemdCgroup:true] PrivilegedWithoutHostDevices:false BaseRuntimeSpec:/etc/containerd/cri-base.json NetworkPluginConfDir: NetworkPluginMaxConfNum:0}] NoPivot:false DisableSnapshotAnnotations:true DiscardUnpackedLayers:true IgnoreRdtNotEnabledErrors:false} CniConfig:{NetworkPluginBinDir:/opt/cni/bin NetworkPluginConfDir:/etc/cni/net.d NetworkPluginMaxConfNum:1 NetworkPluginConfTemplate: IPPreference:} Registry:{ConfigPath: Mirrors:map[] Configs:map[] Auths:map[] Headers:map[]} ImageDecryption:{KeyModel:node} DisableTCPService:true StreamServerAddress:127.0.0.1 StreamServerPort:0 StreamIdleTimeout:4h0m0s EnableSelinux:false SelinuxCategoryRange:1024 SandboxImage:registry.k8s.io/pause:3.7 StatsCollectPeriod:10 SystemdCgroup:false EnableTLSStreaming:false X509KeyPairStreaming:{TLSCertFile: TLSKeyFile:} MaxContainerLogLineSize:16384 DisableCgroup:false DisableApparmor:false RestrictOOMScoreAdj:false MaxConcurrentDownloads:3 DisableProcMount:false UnsetSeccompProfile: TolerateMissingHugetlbController:true DisableHugetlbController:true DeviceOwnershipFromSecurityContext:false IgnoreImageDefinedVolumes:false NetNSMountsUnderStateDir:false EnableUnprivilegedPorts:false EnableUnprivilegedICMP:false} ContainerdRootDir:/var/lib/containerd ContainerdEndpoint:/run/containerd/containerd.sock RootDir:/var/lib/containerd/io.containerd.grpc.v1.cri StateDir:/run/containerd/io.containerd.grpc.v1.cri}"
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.230906144Z" level=info msg="Connect containerd service"
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.231011630Z" level=info msg="Get image filesystem path \"/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs\""
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.231434759Z" level=error msg="failed to load cni during init, please check CRI plugin status before setting up network for pods" error="cni config load failed: no network config found in /etc/cni/net.d: cni plugin not initialized: failed to load cni config"
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.235793404Z" level=info msg="Start subscribing containerd event"
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.236089975Z" level=info msg="Start recovering state"
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.238205305Z" level=warning msg="The image docker.io/kindest/kindnetd:v20230330-48f316cd@sha256:c19d6362a6a928139820761475a38c24c0cf84d507b9ddf414a078cf627497af is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.245285879Z" level=warning msg="The image docker.io/kindest/local-path-helper:v20230330-48f316cd@sha256:135203f2441f916fb13dad1561d27f60a6f11f50ec288b01a7d2ee9947c36270 is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.245603433Z" level=info msg=serving... address=/run/containerd/containerd.sock.ttrpc
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.246173380Z" level=info msg=serving... address=/run/containerd/containerd.sock
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.246229461Z" level=info msg="containerd successfully booted in 0.193711s"
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.299374918Z" level=warning msg="The image docker.io/kindest/local-path-provisioner:v0.0.23-kind.0@sha256:f2d0a02831ff3a03cf51343226670d5060623b43a4cfc4808bd0875b2c4b9501 is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.327909676Z" level=warning msg="The image import-2023-03-30@sha256:3dd2337f70af979c7362b5e52bbdfcb3a5fd39c78d94d02145150cd2db86ba39 is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.339006845Z" level=warning msg="The image import-2023-03-30@sha256:44db4d50a5f9c8efbac0d37ea974d1c0419a5928f90748d3d491a041a00c20b5 is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.352332465Z" level=warning msg="The image import-2023-03-30@sha256:8dbb345de79d1c44f59a7895da702a5f71997ae72aea056609445c397b0c10dc is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.366404613Z" level=warning msg="The image import-2023-03-30@sha256:ba097b515c8c40689733c0f19de377e9bf8995964b7d7150c2045f3dfd166657 is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.393194178Z" level=warning msg="The image registry.k8s.io/coredns/coredns:v1.9.3 is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.400368178Z" level=warning msg="The image registry.k8s.io/etcd:3.5.6-0 is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.409295368Z" level=warning msg="The image registry.k8s.io/kube-apiserver:v1.26.3 is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.429626833Z" level=warning msg="The image registry.k8s.io/kube-controller-manager:v1.26.3 is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.439579902Z" level=warning msg="The image registry.k8s.io/kube-proxy:v1.26.3 is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.444159020Z" level=warning msg="The image registry.k8s.io/kube-scheduler:v1.26.3 is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.457649162Z" level=warning msg="The image registry.k8s.io/pause:3.7 is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.494083429Z" level=warning msg="The image sha256:221177c6082a88ea4f6240ab2450d540955ac6f4d5454f0e15751b653ebda165 is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.496672919Z" level=warning msg="The image sha256:37af659db0ba1408025ceab0e9344dc354a8f38dd9b39875e48b2ad8e2fc3a51 is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.504651499Z" level=warning msg="The image sha256:5185b96f0becf59032b8e3646e99f84d9655dff3ac9e2605e0dc77f9c441ae4a is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.510019929Z" level=warning msg="The image sha256:801fc1f38fa6cb63d4f64438ed884330e86e4be7504f33702e8edcd6fd2118a8 is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.516051051Z" level=warning msg="The image sha256:a329ae3c2c52fe00e9c4eaf48b081cd184ee4bf9aea059e497f4965f0a8deedb is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.522004869Z" level=warning msg="The image sha256:c408b2276bb76627a6f633bf0d26052c208ebd51681c6c89866cc9647471c0bc is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.535425052Z" level=warning msg="The image sha256:cb77c367deebf699996aef822193e3630ce0fe9202b04f809214ff531718fe47 is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.541440256Z" level=warning msg="The image sha256:dec886d0664924af97d276417712f4a065af16e8696ea66afc5a09799e137f8e is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.544311876Z" level=warning msg="The image sha256:eb3079d47a23af78d9b29f246a472fd77838412611e8ccb980a911b34663cc12 is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.561435459Z" level=warning msg="The image sha256:fce326961ae2d51a5f726883fd59d2a8c2ccc3e45d3bb859882db58e422e59e7 is not unpacked."
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.571583897Z" level=info msg="Start event monitor"
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.571713010Z" level=info msg="Start snapshots syncer"
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.571771774Z" level=info msg="Start cni network conf syncer for default"
Apr 14 12:18:39 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:39.571817637Z" level=info msg="Start streaming server"
Apr 14 12:18:47 clusterfuck-control-plane systemd[1]: Reloading.
Apr 14 12:18:47 clusterfuck-control-plane systemd[1]: Starting kubelet: The Kubernetes Node Agent...
Apr 14 12:18:47 clusterfuck-control-plane systemd[1]: Started kubelet: The Kubernetes Node Agent.
Apr 14 12:18:47 clusterfuck-control-plane kubelet[168]: Flag --pod-infra-container-image has been deprecated, will be removed in 1.27. Image garbage collector will get sandbox image information from CRI.
Apr 14 12:18:47 clusterfuck-control-plane kubelet[168]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:47 clusterfuck-control-plane kubelet[168]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:47 clusterfuck-control-plane kubelet[168]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:47 clusterfuck-control-plane kubelet[168]: I0414 12:18:47.831653     168 server.go:198] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
Apr 14 12:18:47 clusterfuck-control-plane kubelet[168]: Flag --pod-infra-container-image has been deprecated, will be removed in 1.27. Image garbage collector will get sandbox image information from CRI.
Apr 14 12:18:47 clusterfuck-control-plane kubelet[168]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:47 clusterfuck-control-plane kubelet[168]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:47 clusterfuck-control-plane kubelet[168]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.100589     168 server.go:412] "Kubelet version" kubeletVersion="v1.26.3"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.100741     168 server.go:414] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.101116     168 server.go:836] "Client rotation is on, will bootstrap in background"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.106603     168 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/ca.crt"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: E0414 12:18:48.107478     168 certificate_manager.go:471] kubernetes.io/kube-apiserver-client-kubelet: Failed while requesting a signed certificate from the control plane: cannot create certificate signing request: Post "https://clusterfuck-control-plane:6443/apis/certificates.k8s.io/v1/certificatesigningrequests": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: W0414 12:18:48.109779     168 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.111517     168 container_manager_linux.go:267] "Container manager verified user specified cgroup-root exists" cgroupRoot=[kubelet]
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.111617     168 container_manager_linux.go:272] "Creating Container Manager object based on Node Config" nodeConfig={RuntimeCgroupsName: SystemCgroupsName: KubeletCgroupsName: KubeletOOMScoreAdj:-999 ContainerRuntime: CgroupsPerQOS:true CgroupRoot:/kubelet CgroupDriver:systemd KubeletRootDir:/var/lib/kubelet ProtectKernelDefaults:false NodeAllocatableConfig:{KubeReservedCgroupName: SystemReservedCgroupName: ReservedSystemCPUs: EnforceNodeAllocatable:map[pods:{}] KubeReserved:map[] SystemReserved:map[] HardEvictionThresholds:[]} QOSReserved:map[] CPUManagerPolicy:none CPUManagerPolicyOptions:map[] ExperimentalTopologyManagerScope:container CPUManagerReconcilePeriod:10s ExperimentalMemoryManagerPolicy:None ExperimentalMemoryManagerReservedMemory:[] ExperimentalPodPidsLimit:-1 EnforceCPULimits:true CPUCFSQuotaPeriod:100ms ExperimentalTopologyManagerPolicy:none ExperimentalTopologyManagerPolicyOptions:map[]}
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.111639     168 topology_manager.go:134] "Creating topology manager with policy per scope" topologyPolicyName="none" topologyScopeName="container"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.111654     168 container_manager_linux.go:308] "Creating device plugin manager"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.111780     168 state_mem.go:36] "Initialized new in-memory state store"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.118145     168 kubelet.go:398] "Attempting to sync node with API server"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.118213     168 kubelet.go:286] "Adding static pod path" path="/etc/kubernetes/manifests"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.118238     168 kubelet.go:297] "Adding apiserver pod source"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.118259     168 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.120617     168 kuberuntime_manager.go:244] "Container runtime initialized" containerRuntime="containerd" version="v1.6.19-46-g941215f49" apiVersion="v1"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: W0414 12:18:48.120873     168 probe.go:268] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.121292     168 server.go:1186] "Started kubelet"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.122736     168 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.126662     168 server.go:161] "Starting to listen" address="0.0.0.0" port=10250
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: W0414 12:18:48.127427     168 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://clusterfuck-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dclusterfuck-control-plane&limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: E0414 12:18:48.127503     168 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://clusterfuck-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dclusterfuck-control-plane&limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: W0414 12:18:48.127581     168 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://clusterfuck-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: E0414 12:18:48.127647     168 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://clusterfuck-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.128303     168 volume_manager.go:293] "Starting Kubelet Volume Manager"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.128618     168 desired_state_of_world_populator.go:151] "Desired state populator starts to run"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.130993     168 server.go:451] "Adding debug handlers to kubelet server"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: W0414 12:18:48.134686     168 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: Get "https://clusterfuck-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: E0414 12:18:48.134763     168 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://clusterfuck-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: E0414 12:18:48.138181     168 event.go:276] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b3c76f995", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 48, 121268629, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 48, 121268629, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://clusterfuck-control-plane:6443/api/v1/namespaces/default/events": dial tcp 172.21.0.5:6443: connect: connection refused'(may retry after sleeping)
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: E0414 12:18:48.150165     168 controller.go:146] failed to ensure lease exists, will retry in 200ms, error: Get "https://clusterfuck-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/clusterfuck-control-plane?timeout=10s": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.158190     168 cpu_manager.go:214] "Starting CPU manager" policy="none"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.158242     168 cpu_manager.go:215] "Reconciling" reconcilePeriod="10s"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.158260     168 state_mem.go:36] "Initialized new in-memory state store"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.161669     168 policy_none.go:49] "None policy: Start"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.162889     168 memory_manager.go:169] "Starting memorymanager" policy="None"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.162943     168 state_mem.go:35] "Initializing new in-memory state store"
Apr 14 12:18:48 clusterfuck-control-plane systemd[1]: Created slice libcontainer container kubelet-kubepods.slice.
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.193412     168 kubelet_network_linux.go:63] "Initialized iptables rules." protocol=IPv4
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: E0414 12:18:48.193810     168 kubelet.go:1466] "Failed to start ContainerManager" err="failed to initialize top level QOS containers: root container [kubelet kubepods] doesn't exist"
Apr 14 12:18:48 clusterfuck-control-plane systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Apr 14 12:18:48 clusterfuck-control-plane systemd[1]: kubelet.service: Failed with result 'exit-code'.
Apr 14 12:18:49 clusterfuck-control-plane systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 1.
Apr 14 12:18:49 clusterfuck-control-plane systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Apr 14 12:18:49 clusterfuck-control-plane systemd[1]: Starting kubelet: The Kubernetes Node Agent...
Apr 14 12:18:49 clusterfuck-control-plane systemd[1]: Started kubelet: The Kubernetes Node Agent.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: Flag --pod-infra-container-image has been deprecated, will be removed in 1.27. Image garbage collector will get sandbox image information from CRI.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.387800     217 server.go:198] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: Flag --pod-infra-container-image has been deprecated, will be removed in 1.27. Image garbage collector will get sandbox image information from CRI.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.392559     217 server.go:412] "Kubelet version" kubeletVersion="v1.26.3"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.392616     217 server.go:414] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.392898     217 server.go:836] "Client rotation is on, will bootstrap in background"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.394333     217 certificate_store.go:130] Loading cert/key pair from "/var/lib/kubelet/pki/kubelet-client-current.pem".
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: W0414 12:18:49.396807     217 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.398180     217 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/ca.crt"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.398549     217 container_manager_linux.go:267] "Container manager verified user specified cgroup-root exists" cgroupRoot=[kubelet]
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.398702     217 container_manager_linux.go:272] "Creating Container Manager object based on Node Config" nodeConfig={RuntimeCgroupsName: SystemCgroupsName: KubeletCgroupsName: KubeletOOMScoreAdj:-999 ContainerRuntime: CgroupsPerQOS:true CgroupRoot:/kubelet CgroupDriver:systemd KubeletRootDir:/var/lib/kubelet ProtectKernelDefaults:false NodeAllocatableConfig:{KubeReservedCgroupName: SystemReservedCgroupName: ReservedSystemCPUs: EnforceNodeAllocatable:map[pods:{}] KubeReserved:map[] SystemReserved:map[] HardEvictionThresholds:[]} QOSReserved:map[] CPUManagerPolicy:none CPUManagerPolicyOptions:map[] ExperimentalTopologyManagerScope:container CPUManagerReconcilePeriod:10s ExperimentalMemoryManagerPolicy:None ExperimentalMemoryManagerReservedMemory:[] ExperimentalPodPidsLimit:-1 EnforceCPULimits:true CPUCFSQuotaPeriod:100ms ExperimentalTopologyManagerPolicy:none ExperimentalTopologyManagerPolicyOptions:map[]}
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.398856     217 topology_manager.go:134] "Creating topology manager with policy per scope" topologyPolicyName="none" topologyScopeName="container"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.398965     217 container_manager_linux.go:308] "Creating device plugin manager"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.399029     217 state_mem.go:36] "Initialized new in-memory state store"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.406667     217 kubelet.go:398] "Attempting to sync node with API server"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.406721     217 kubelet.go:286] "Adding static pod path" path="/etc/kubernetes/manifests"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.406745     217 kubelet.go:297] "Adding apiserver pod source"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.406759     217 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.408157     217 kuberuntime_manager.go:244] "Container runtime initialized" containerRuntime="containerd" version="v1.6.19-46-g941215f49" apiVersion="v1"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.408674     217 server.go:1186] "Started kubelet"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.410939     217 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: W0414 12:18:49.413722     217 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://clusterfuck-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dclusterfuck-control-plane&limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.414055     217 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://clusterfuck-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dclusterfuck-control-plane&limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: W0414 12:18:49.414410     217 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://clusterfuck-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.414509     217 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://clusterfuck-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.415112     217 server.go:161] "Starting to listen" address="0.0.0.0" port=10250
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.416364     217 server.go:451] "Adding debug handlers to kubelet server"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.420527     217 volume_manager.go:293] "Starting Kubelet Volume Manager"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.420696     217 desired_state_of_world_populator.go:151] "Desired state populator starts to run"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: W0414 12:18:49.423866     217 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: Get "https://clusterfuck-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.423928     217 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://clusterfuck-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.424902     217 event.go:276] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b89326475", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 408619637, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 408619637, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://clusterfuck-control-plane:6443/api/v1/namespaces/default/events": dial tcp 172.21.0.5:6443: connect: connection refused'(may retry after sleeping)
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.438738     217 controller.go:146] failed to ensure lease exists, will retry in 200ms, error: Get "https://clusterfuck-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/clusterfuck-control-plane?timeout=10s": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.447882     217 cpu_manager.go:214] "Starting CPU manager" policy="none"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.447932     217 cpu_manager.go:215] "Reconciling" reconcilePeriod="10s"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.447951     217 state_mem.go:36] "Initialized new in-memory state store"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.448087     217 state_mem.go:88] "Updated default CPUSet" cpuSet=""
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.448099     217 state_mem.go:96] "Updated CPUSet assignments" assignments=map[]
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.448104     217 policy_none.go:49] "None policy: Start"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.449152     217 memory_manager.go:169] "Starting memorymanager" policy="None"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.449244     217 state_mem.go:35] "Initializing new in-memory state store"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.449409     217 state_mem.go:75] "Updated machine memory state"
Apr 14 12:18:49 clusterfuck-control-plane systemd[1]: Created slice libcontainer container kubelet-kubepods-burstable.slice.
Apr 14 12:18:49 clusterfuck-control-plane systemd[1]: Created slice libcontainer container kubelet-kubepods-besteffort.slice.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.478172     217 manager.go:455] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.478504     217 plugin_manager.go:118] "Starting Kubelet Plugin Manager"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.479977     217 eviction_manager.go:261] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"clusterfuck-control-plane\" not found"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.481615     217 kubelet_network_linux.go:63] "Initialized iptables rules." protocol=IPv4
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.518014     217 kubelet_network_linux.go:63] "Initialized iptables rules." protocol=IPv6
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.518143     217 status_manager.go:176] "Starting to sync pod status with apiserver"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.518386     217 kubelet.go:2113] "Starting kubelet main sync loop"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.518491     217 kubelet.go:2137] "Skipping pod synchronization" err="PLEG is not healthy: pleg has yet to be successful"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: W0414 12:18:49.519913     217 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.RuntimeClass: Get "https://clusterfuck-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.520047     217 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://clusterfuck-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.522108     217 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.522624     217 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://clusterfuck-control-plane:6443/api/v1/nodes\": dial tcp 172.21.0.5:6443: connect: connection refused" node="clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.618871     217 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.620043     217 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.620663     217 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.621479     217 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.621899     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/bc029fa94725104014953f288b5111db-ca-certs\") pod \"kube-apiserver-clusterfuck-control-plane\" (UID: \"bc029fa94725104014953f288b5111db\") " pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.621994     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bc029fa94725104014953f288b5111db-etc-ca-certificates\") pod \"kube-apiserver-clusterfuck-control-plane\" (UID: \"bc029fa94725104014953f288b5111db\") " pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.622100     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bc029fa94725104014953f288b5111db-usr-local-share-ca-certificates\") pod \"kube-apiserver-clusterfuck-control-plane\" (UID: \"bc029fa94725104014953f288b5111db\") " pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.622163     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bc029fa94725104014953f288b5111db-usr-share-ca-certificates\") pod \"kube-apiserver-clusterfuck-control-plane\" (UID: \"bc029fa94725104014953f288b5111db\") " pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.622273     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-certs\" (UniqueName: \"kubernetes.io/host-path/cf4141b3b06b4295e10fda6cee69dc09-etcd-certs\") pod \"etcd-clusterfuck-control-plane\" (UID: \"cf4141b3b06b4295e10fda6cee69dc09\") " pod="kube-system/etcd-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.622419     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/bc029fa94725104014953f288b5111db-k8s-certs\") pod \"kube-apiserver-clusterfuck-control-plane\" (UID: \"bc029fa94725104014953f288b5111db\") " pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.622503     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-usr-local-share-ca-certificates\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.622676     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-usr-share-ca-certificates\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.622755     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-data\" (UniqueName: \"kubernetes.io/host-path/cf4141b3b06b4295e10fda6cee69dc09-etcd-data\") pod \"etcd-clusterfuck-control-plane\" (UID: \"cf4141b3b06b4295e10fda6cee69dc09\") " pod="kube-system/etcd-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.622890     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-ca-certs\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.622980     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-etc-ca-certificates\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.623069     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"flexvolume-dir\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-flexvolume-dir\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.623129     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-k8s-certs\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.623203     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-kubeconfig\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.623158     217 status_manager.go:698] "Failed to get status for pod" podUID=bc029fa94725104014953f288b5111db pod="kube-system/kube-apiserver-clusterfuck-control-plane" err="Get \"https://clusterfuck-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-clusterfuck-control-plane\": dial tcp 172.21.0.5:6443: connect: connection refused"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.624142     217 status_manager.go:698] "Failed to get status for pod" podUID=cf4141b3b06b4295e10fda6cee69dc09 pod="kube-system/etcd-clusterfuck-control-plane" err="Get \"https://clusterfuck-control-plane:6443/api/v1/namespaces/kube-system/pods/etcd-clusterfuck-control-plane\": dial tcp 172.21.0.5:6443: connect: connection refused"
Apr 14 12:18:49 clusterfuck-control-plane systemd[1]: Created slice libcontainer container kubelet-kubepods-burstable-podbc029fa94725104014953f288b5111db.slice.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.631834     217 status_manager.go:698] "Failed to get status for pod" podUID=ba2bfe9fab65c7374db97567e0331986 pod="kube-system/kube-controller-manager-clusterfuck-control-plane" err="Get \"https://clusterfuck-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-clusterfuck-control-plane\": dial tcp 172.21.0.5:6443: connect: connection refused"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.632290     217 status_manager.go:698] "Failed to get status for pod" podUID=52a49c1dda96443061d997ca66c5aae7 pod="kube-system/kube-scheduler-clusterfuck-control-plane" err="Get \"https://clusterfuck-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-clusterfuck-control-plane\": dial tcp 172.21.0.5:6443: connect: connection refused"
Apr 14 12:18:49 clusterfuck-control-plane systemd[1]: Created slice libcontainer container kubelet-kubepods-burstable-podcf4141b3b06b4295e10fda6cee69dc09.slice.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.640538     217 controller.go:146] failed to ensure lease exists, will retry in 400ms, error: Get "https://clusterfuck-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/clusterfuck-control-plane?timeout=10s": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:49 clusterfuck-control-plane systemd[1]: Created slice libcontainer container kubelet-kubepods-burstable-podba2bfe9fab65c7374db97567e0331986.slice.
Apr 14 12:18:49 clusterfuck-control-plane systemd[1]: Created slice libcontainer container kubelet-kubepods-burstable-pod52a49c1dda96443061d997ca66c5aae7.slice.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.723403     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/52a49c1dda96443061d997ca66c5aae7-kubeconfig\") pod \"kube-scheduler-clusterfuck-control-plane\" (UID: \"52a49c1dda96443061d997ca66c5aae7\") " pod="kube-system/kube-scheduler-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.723800     217 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.724414     217 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://clusterfuck-control-plane:6443/api/v1/nodes\": dial tcp 172.21.0.5:6443: connect: connection refused" node="clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:49.937504020Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-apiserver-clusterfuck-control-plane,Uid:bc029fa94725104014953f288b5111db,Namespace:kube-system,Attempt:0,}"
Apr 14 12:18:49 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:49.953621867Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:etcd-clusterfuck-control-plane,Uid:cf4141b3b06b4295e10fda6cee69dc09,Namespace:kube-system,Attempt:0,}"
Apr 14 12:18:49 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:49.957074564Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-controller-manager-clusterfuck-control-plane,Uid:ba2bfe9fab65c7374db97567e0331986,Namespace:kube-system,Attempt:0,}"
Apr 14 12:18:49 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:49.959204870Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-scheduler-clusterfuck-control-plane,Uid:52a49c1dda96443061d997ca66c5aae7,Namespace:kube-system,Attempt:0,}"
Apr 14 12:18:50 clusterfuck-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount369399573.mount: Deactivated successfully.
Apr 14 12:18:50 clusterfuck-control-plane kubelet[217]: E0414 12:18:50.041953     217 controller.go:146] failed to ensure lease exists, will retry in 800ms, error: Get "https://clusterfuck-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/clusterfuck-control-plane?timeout=10s": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:50 clusterfuck-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount4065316544.mount: Deactivated successfully.
Apr 14 12:18:50 clusterfuck-control-plane kubelet[217]: I0414 12:18:50.126197     217 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-control-plane"
Apr 14 12:18:50 clusterfuck-control-plane kubelet[217]: E0414 12:18:50.126702     217 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://clusterfuck-control-plane:6443/api/v1/nodes\": dial tcp 172.21.0.5:6443: connect: connection refused" node="clusterfuck-control-plane"
Apr 14 12:18:50 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:50.369255319Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 14 12:18:50 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:50.369315856Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 14 12:18:50 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:50.369325681Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 14 12:18:50 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:50.369644738Z" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/35113d4af837d43fbec31cc5c6e730904b6254e24adfeef7510744a6f155b2d1 pid=292 runtime=io.containerd.runc.v2
Apr 14 12:18:50 clusterfuck-control-plane kubelet[217]: W0414 12:18:50.423429     217 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://clusterfuck-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dclusterfuck-control-plane&limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:50 clusterfuck-control-plane kubelet[217]: E0414 12:18:50.423489     217 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://clusterfuck-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dclusterfuck-control-plane&limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:50 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:50.540960859Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 14 12:18:50 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:50.541011411Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 14 12:18:50 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:50.541021869Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 14 12:18:50 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:50.544042703Z" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/9a30716b3c4d450d4ba8f60e7cb7dac1ba95dbae16219150c6ac490b61ba2124 pid=319 runtime=io.containerd.runc.v2
Apr 14 12:18:50 clusterfuck-control-plane systemd[1]: Started libcontainer container 35113d4af837d43fbec31cc5c6e730904b6254e24adfeef7510744a6f155b2d1.
Apr 14 12:18:50 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:50.555844611Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 14 12:18:50 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:50.555998906Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 14 12:18:50 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:50.556096647Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 14 12:18:50 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:50.566965295Z" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/8d9e7df3676ab59b1cac71c54c2d1b0d203d1aa94e8e87853d07099cc71cb398 pid=328 runtime=io.containerd.runc.v2
Apr 14 12:18:50 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:50.651876834Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 14 12:18:50 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:50.651924780Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 14 12:18:50 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:50.651941902Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 14 12:18:50 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:50.652293167Z" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/648c2493b7690b719e293e0385fa2137e03480be5773bf5a14decc39240964ff pid=368 runtime=io.containerd.runc.v2
Apr 14 12:18:50 clusterfuck-control-plane systemd[1]: Started libcontainer container 9a30716b3c4d450d4ba8f60e7cb7dac1ba95dbae16219150c6ac490b61ba2124.
Apr 14 12:18:50 clusterfuck-control-plane kubelet[217]: W0414 12:18:50.677936     217 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: Get "https://clusterfuck-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:50 clusterfuck-control-plane kubelet[217]: E0414 12:18:50.678018     217 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://clusterfuck-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:50 clusterfuck-control-plane kubelet[217]: W0414 12:18:50.678074     217 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://clusterfuck-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:50 clusterfuck-control-plane kubelet[217]: E0414 12:18:50.678113     217 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://clusterfuck-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:50 clusterfuck-control-plane systemd[1]: Started libcontainer container 8d9e7df3676ab59b1cac71c54c2d1b0d203d1aa94e8e87853d07099cc71cb398.
Apr 14 12:18:50 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:50.713061791Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-controller-manager-clusterfuck-control-plane,Uid:ba2bfe9fab65c7374db97567e0331986,Namespace:kube-system,Attempt:0,} returns sandbox id \"35113d4af837d43fbec31cc5c6e730904b6254e24adfeef7510744a6f155b2d1\""
Apr 14 12:18:50 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:50.729569934Z" level=info msg="CreateContainer within sandbox \"35113d4af837d43fbec31cc5c6e730904b6254e24adfeef7510744a6f155b2d1\" for container &ContainerMetadata{Name:kube-controller-manager,Attempt:0,}"
Apr 14 12:18:50 clusterfuck-control-plane systemd[1]: Started libcontainer container 648c2493b7690b719e293e0385fa2137e03480be5773bf5a14decc39240964ff.
Apr 14 12:18:50 clusterfuck-control-plane kubelet[217]: E0414 12:18:50.844237     217 controller.go:146] failed to ensure lease exists, will retry in 1.6s, error: Get "https://clusterfuck-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/clusterfuck-control-plane?timeout=10s": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:51 clusterfuck-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount662759475.mount: Deactivated successfully.
Apr 14 12:18:51 clusterfuck-control-plane kubelet[217]: I0414 12:18:51.042999     217 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-control-plane"
Apr 14 12:18:51 clusterfuck-control-plane kubelet[217]: E0414 12:18:51.043417     217 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://clusterfuck-control-plane:6443/api/v1/nodes\": dial tcp 172.21.0.5:6443: connect: connection refused" node="clusterfuck-control-plane"
Apr 14 12:18:51 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:51.058143995Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:etcd-clusterfuck-control-plane,Uid:cf4141b3b06b4295e10fda6cee69dc09,Namespace:kube-system,Attempt:0,} returns sandbox id \"8d9e7df3676ab59b1cac71c54c2d1b0d203d1aa94e8e87853d07099cc71cb398\""
Apr 14 12:18:51 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:51.058310566Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-apiserver-clusterfuck-control-plane,Uid:bc029fa94725104014953f288b5111db,Namespace:kube-system,Attempt:0,} returns sandbox id \"9a30716b3c4d450d4ba8f60e7cb7dac1ba95dbae16219150c6ac490b61ba2124\""
Apr 14 12:18:51 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:51.063768313Z" level=info msg="CreateContainer within sandbox \"9a30716b3c4d450d4ba8f60e7cb7dac1ba95dbae16219150c6ac490b61ba2124\" for container &ContainerMetadata{Name:kube-apiserver,Attempt:0,}"
Apr 14 12:18:51 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:51.063977411Z" level=info msg="CreateContainer within sandbox \"8d9e7df3676ab59b1cac71c54c2d1b0d203d1aa94e8e87853d07099cc71cb398\" for container &ContainerMetadata{Name:etcd,Attempt:0,}"
Apr 14 12:18:51 clusterfuck-control-plane kubelet[217]: W0414 12:18:51.113020     217 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.RuntimeClass: Get "https://clusterfuck-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:51 clusterfuck-control-plane kubelet[217]: E0414 12:18:51.113068     217 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://clusterfuck-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:51 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:51.148177193Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-scheduler-clusterfuck-control-plane,Uid:52a49c1dda96443061d997ca66c5aae7,Namespace:kube-system,Attempt:0,} returns sandbox id \"648c2493b7690b719e293e0385fa2137e03480be5773bf5a14decc39240964ff\""
Apr 14 12:18:51 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:51.151533314Z" level=info msg="CreateContainer within sandbox \"648c2493b7690b719e293e0385fa2137e03480be5773bf5a14decc39240964ff\" for container &ContainerMetadata{Name:kube-scheduler,Attempt:0,}"
Apr 14 12:18:51 clusterfuck-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount2883281461.mount: Deactivated successfully.
Apr 14 12:18:52 clusterfuck-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount945682181.mount: Deactivated successfully.
Apr 14 12:18:52 clusterfuck-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount3286079089.mount: Deactivated successfully.
Apr 14 12:18:52 clusterfuck-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount1567056164.mount: Deactivated successfully.
Apr 14 12:18:52 clusterfuck-control-plane kubelet[217]: W0414 12:18:52.094690     217 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://clusterfuck-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dclusterfuck-control-plane&limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:52 clusterfuck-control-plane kubelet[217]: E0414 12:18:52.094740     217 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://clusterfuck-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dclusterfuck-control-plane&limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:52 clusterfuck-control-plane kubelet[217]: E0414 12:18:52.445846     217 controller.go:146] failed to ensure lease exists, will retry in 3.2s, error: Get "https://clusterfuck-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/clusterfuck-control-plane?timeout=10s": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:52 clusterfuck-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount2297089665.mount: Deactivated successfully.
Apr 14 12:18:52 clusterfuck-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount1280355011.mount: Deactivated successfully.
Apr 14 12:18:52 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:52.481676987Z" level=info msg="CreateContainer within sandbox \"648c2493b7690b719e293e0385fa2137e03480be5773bf5a14decc39240964ff\" for &ContainerMetadata{Name:kube-scheduler,Attempt:0,} returns container id \"1784b521c7ab2ff76cbaab0c9a6471962b00d111ced7c0cae72d21b9b0dd9de9\""
Apr 14 12:18:52 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:52.482267324Z" level=info msg="CreateContainer within sandbox \"35113d4af837d43fbec31cc5c6e730904b6254e24adfeef7510744a6f155b2d1\" for &ContainerMetadata{Name:kube-controller-manager,Attempt:0,} returns container id \"ddebffa0a17beb6b75720f0ae526b21b94f8d2048fa8ae044642c6a606f9ef86\""
Apr 14 12:18:52 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:52.482953589Z" level=info msg="StartContainer for \"1784b521c7ab2ff76cbaab0c9a6471962b00d111ced7c0cae72d21b9b0dd9de9\""
Apr 14 12:18:52 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:52.509082487Z" level=info msg="StartContainer for \"ddebffa0a17beb6b75720f0ae526b21b94f8d2048fa8ae044642c6a606f9ef86\""
Apr 14 12:18:52 clusterfuck-control-plane systemd[1]: Started libcontainer container 1784b521c7ab2ff76cbaab0c9a6471962b00d111ced7c0cae72d21b9b0dd9de9.
Apr 14 12:18:52 clusterfuck-control-plane systemd[1]: Started libcontainer container ddebffa0a17beb6b75720f0ae526b21b94f8d2048fa8ae044642c6a606f9ef86.
Apr 14 12:18:52 clusterfuck-control-plane kubelet[217]: I0414 12:18:52.654604     217 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-control-plane"
Apr 14 12:18:52 clusterfuck-control-plane kubelet[217]: E0414 12:18:52.655265     217 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://clusterfuck-control-plane:6443/api/v1/nodes\": dial tcp 172.21.0.5:6443: connect: connection refused" node="clusterfuck-control-plane"
Apr 14 12:18:52 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:52.719383831Z" level=info msg="CreateContainer within sandbox \"9a30716b3c4d450d4ba8f60e7cb7dac1ba95dbae16219150c6ac490b61ba2124\" for &ContainerMetadata{Name:kube-apiserver,Attempt:0,} returns container id \"4d861bc483d7fcbaa3de1a286c3d079c41766a44ca6f1eb6a5de67b38581b3f2\""
Apr 14 12:18:52 clusterfuck-control-plane kubelet[217]: W0414 12:18:52.719784     217 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://clusterfuck-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:52 clusterfuck-control-plane kubelet[217]: E0414 12:18:52.720112     217 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://clusterfuck-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:52 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:52.721183993Z" level=info msg="StartContainer for \"4d861bc483d7fcbaa3de1a286c3d079c41766a44ca6f1eb6a5de67b38581b3f2\""
Apr 14 12:18:52 clusterfuck-control-plane systemd[1]: Started libcontainer container 4d861bc483d7fcbaa3de1a286c3d079c41766a44ca6f1eb6a5de67b38581b3f2.
Apr 14 12:18:52 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:52.829408875Z" level=info msg="StartContainer for \"1784b521c7ab2ff76cbaab0c9a6471962b00d111ced7c0cae72d21b9b0dd9de9\" returns successfully"
Apr 14 12:18:52 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:52.833644451Z" level=info msg="StartContainer for \"ddebffa0a17beb6b75720f0ae526b21b94f8d2048fa8ae044642c6a606f9ef86\" returns successfully"
Apr 14 12:18:52 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:52.986855961Z" level=info msg="StartContainer for \"4d861bc483d7fcbaa3de1a286c3d079c41766a44ca6f1eb6a5de67b38581b3f2\" returns successfully"
Apr 14 12:18:55 clusterfuck-control-plane kubelet[217]: I0414 12:18:55.856342     217 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-control-plane"
Apr 14 12:18:57 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:57.252428961Z" level=info msg="CreateContainer within sandbox \"8d9e7df3676ab59b1cac71c54c2d1b0d203d1aa94e8e87853d07099cc71cb398\" for &ContainerMetadata{Name:etcd,Attempt:0,} returns container id \"2bc0639ec4d801f978dd4323ebc4cdcebb5052a0b0bb2e8c54dd9223f14e5301\""
Apr 14 12:18:57 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:57.253432303Z" level=info msg="StartContainer for \"2bc0639ec4d801f978dd4323ebc4cdcebb5052a0b0bb2e8c54dd9223f14e5301\""
Apr 14 12:18:57 clusterfuck-control-plane systemd[1]: Started libcontainer container 2bc0639ec4d801f978dd4323ebc4cdcebb5052a0b0bb2e8c54dd9223f14e5301.
Apr 14 12:18:57 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:18:57.378204480Z" level=info msg="StartContainer for \"2bc0639ec4d801f978dd4323ebc4cdcebb5052a0b0bb2e8c54dd9223f14e5301\" returns successfully"
Apr 14 12:18:59 clusterfuck-control-plane kubelet[217]: E0414 12:18:59.480901     217 eviction_manager.go:261] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"clusterfuck-control-plane\" not found"
Apr 14 12:19:00 clusterfuck-control-plane kubelet[217]: E0414 12:19:00.684914     217 nodelease.go:49] "Failed to get node when trying to set owner ref to the node lease" err="nodes \"clusterfuck-control-plane\" not found" node="clusterfuck-control-plane"
Apr 14 12:19:00 clusterfuck-control-plane kubelet[217]: I0414 12:19:00.822073     217 kubelet_node_status.go:73] "Successfully registered node" node="clusterfuck-control-plane"
Apr 14 12:19:00 clusterfuck-control-plane kubelet[217]: E0414 12:19:00.844268     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b89326475", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 408619637, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 408619637, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:00 clusterfuck-control-plane kubelet[217]: E0414 12:19:00.903613     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b8b6e141b", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node clusterfuck-control-plane status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446085659, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446085659, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:00 clusterfuck-control-plane kubelet[217]: E0414 12:19:00.964495     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b8b6e3499", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node clusterfuck-control-plane status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446093977, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446093977, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: E0414 12:19:01.020478     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b8b6e4287", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node clusterfuck-control-plane status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446097543, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446097543, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: E0414 12:19:01.074347     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b8d6e7d87", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeAllocatableEnforced", Message:"Updated Node Allocatable limit across pods", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 479667079, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 479667079, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: E0414 12:19:01.130609     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b8b6e141b", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node clusterfuck-control-plane status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446085659, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 522076233, time.Local), Count:2, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: E0414 12:19:01.186724     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b8b6e3499", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node clusterfuck-control-plane status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446093977, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 522081246, time.Local), Count:2, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: E0414 12:19:01.243510     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b8b6e4287", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node clusterfuck-control-plane status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446097543, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 522085610, time.Local), Count:2, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: E0414 12:19:01.301083     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b8b6e141b", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node clusterfuck-control-plane status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446085659, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 619965180, time.Local), Count:3, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: I0414 12:19:01.427629     217 apiserver.go:52] "Watching apiserver"
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: I0414 12:19:01.520864     217 desired_state_of_world_populator.go:159] "Finished populating initial desired state of world"
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: I0414 12:19:01.547631     217 reconciler.go:41] "Reconciler: start to sync state"
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: E0414 12:19:01.596275     217 kubelet.go:1802] "Failed creating a mirror pod for" err="pods \"kube-controller-manager-clusterfuck-control-plane\" is forbidden: no PriorityClass with name system-node-critical was found" pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: E0414 12:19:01.698124     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b8b6e3499", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node clusterfuck-control-plane status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446093977, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 619974204, time.Local), Count:3, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:02 clusterfuck-control-plane kubelet[217]: E0414 12:19:02.100421     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b8b6e4287", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node clusterfuck-control-plane status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446097543, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 619977492, time.Local), Count:3, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:03 clusterfuck-control-plane systemd[1]: Reloading.
Apr 14 12:19:03 clusterfuck-control-plane systemd[1]: Stopping kubelet: The Kubernetes Node Agent...
Apr 14 12:19:03 clusterfuck-control-plane kubelet[217]: I0414 12:19:03.543228     217 dynamic_cafile_content.go:171] "Shutting down controller" name="client-ca-bundle::/etc/kubernetes/pki/ca.crt"
Apr 14 12:19:03 clusterfuck-control-plane systemd[1]: kubelet.service: Deactivated successfully.
Apr 14 12:19:03 clusterfuck-control-plane systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Apr 14 12:19:03 clusterfuck-control-plane systemd[1]: Starting kubelet: The Kubernetes Node Agent...
Apr 14 12:19:03 clusterfuck-control-plane systemd[1]: Started kubelet: The Kubernetes Node Agent.
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: Flag --pod-infra-container-image has been deprecated, will be removed in 1.27. Image garbage collector will get sandbox image information from CRI.
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.685537     664 server.go:198] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: Flag --pod-infra-container-image has been deprecated, will be removed in 1.27. Image garbage collector will get sandbox image information from CRI.
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.689514     664 server.go:412] "Kubelet version" kubeletVersion="v1.26.3"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.689628     664 server.go:414] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.689889     664 server.go:836] "Client rotation is on, will bootstrap in background"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.691040     664 certificate_store.go:130] Loading cert/key pair from "/var/lib/kubelet/pki/kubelet-client-current.pem".
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.691923     664 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/ca.crt"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: W0414 12:19:03.694593     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.698818     664 container_manager_linux.go:267] "Container manager verified user specified cgroup-root exists" cgroupRoot=[kubelet]
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.698898     664 container_manager_linux.go:272] "Creating Container Manager object based on Node Config" nodeConfig={RuntimeCgroupsName: SystemCgroupsName: KubeletCgroupsName: KubeletOOMScoreAdj:-999 ContainerRuntime: CgroupsPerQOS:true CgroupRoot:/kubelet CgroupDriver:systemd KubeletRootDir:/var/lib/kubelet ProtectKernelDefaults:false NodeAllocatableConfig:{KubeReservedCgroupName: SystemReservedCgroupName: ReservedSystemCPUs: EnforceNodeAllocatable:map[pods:{}] KubeReserved:map[] SystemReserved:map[] HardEvictionThresholds:[]} QOSReserved:map[] CPUManagerPolicy:none CPUManagerPolicyOptions:map[] ExperimentalTopologyManagerScope:container CPUManagerReconcilePeriod:10s ExperimentalMemoryManagerPolicy:None ExperimentalMemoryManagerReservedMemory:[] ExperimentalPodPidsLimit:-1 EnforceCPULimits:true CPUCFSQuotaPeriod:100ms ExperimentalTopologyManagerPolicy:none ExperimentalTopologyManagerPolicyOptions:map[]}
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.698925     664 topology_manager.go:134] "Creating topology manager with policy per scope" topologyPolicyName="none" topologyScopeName="container"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.698938     664 container_manager_linux.go:308] "Creating device plugin manager"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.698964     664 state_mem.go:36] "Initialized new in-memory state store"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.703146     664 kubelet.go:398] "Attempting to sync node with API server"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.703203     664 kubelet.go:286] "Adding static pod path" path="/etc/kubernetes/manifests"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.703228     664 kubelet.go:297] "Adding apiserver pod source"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.703238     664 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.706161     664 kuberuntime_manager.go:244] "Container runtime initialized" containerRuntime="containerd" version="v1.6.19-46-g941215f49" apiVersion="v1"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.706531     664 server.go:1186] "Started kubelet"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.710258     664 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.717004     664 volume_manager.go:293] "Starting Kubelet Volume Manager"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.719129     664 desired_state_of_world_populator.go:151] "Desired state populator starts to run"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.722102     664 server.go:161] "Starting to listen" address="0.0.0.0" port=10250
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.722984     664 server.go:451] "Adding debug handlers to kubelet server"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.766984     664 kubelet_network_linux.go:63] "Initialized iptables rules." protocol=IPv4
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.821252     664 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-control-plane"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.841395     664 kubelet_network_linux.go:63] "Initialized iptables rules." protocol=IPv6
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.841447     664 status_manager.go:176] "Starting to sync pod status with apiserver"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.841468     664 kubelet.go:2113] "Starting kubelet main sync loop"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: E0414 12:19:03.841653     664 kubelet.go:2137] "Skipping pod synchronization" err="[container runtime status check may not have completed yet, PLEG is not healthy: pleg has yet to be successful]"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.868756     664 kubelet_node_status.go:108] "Node was previously registered" node="clusterfuck-control-plane"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.868878     664 kubelet_node_status.go:73] "Successfully registered node" node="clusterfuck-control-plane"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.878483     664 cpu_manager.go:214] "Starting CPU manager" policy="none"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.878534     664 cpu_manager.go:215] "Reconciling" reconcilePeriod="10s"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.878616     664 state_mem.go:36] "Initialized new in-memory state store"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.878850     664 state_mem.go:88] "Updated default CPUSet" cpuSet=""
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.878879     664 state_mem.go:96] "Updated CPUSet assignments" assignments=map[]
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.878889     664 policy_none.go:49] "None policy: Start"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.880002     664 memory_manager.go:169] "Starting memorymanager" policy="None"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.880061     664 state_mem.go:35] "Initializing new in-memory state store"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.880266     664 state_mem.go:75] "Updated machine memory state"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.890202     664 manager.go:455] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.890495     664 plugin_manager.go:118] "Starting Kubelet Plugin Manager"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.942336     664 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.942462     664 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.943545     664 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.943611     664 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120674     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-etc-ca-certificates\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120751     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-k8s-certs\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120774     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/bc029fa94725104014953f288b5111db-ca-certs\") pod \"kube-apiserver-clusterfuck-control-plane\" (UID: \"bc029fa94725104014953f288b5111db\") " pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120791     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/52a49c1dda96443061d997ca66c5aae7-kubeconfig\") pod \"kube-scheduler-clusterfuck-control-plane\" (UID: \"52a49c1dda96443061d997ca66c5aae7\") " pod="kube-system/kube-scheduler-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120809     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bc029fa94725104014953f288b5111db-etc-ca-certificates\") pod \"kube-apiserver-clusterfuck-control-plane\" (UID: \"bc029fa94725104014953f288b5111db\") " pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120824     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/bc029fa94725104014953f288b5111db-k8s-certs\") pod \"kube-apiserver-clusterfuck-control-plane\" (UID: \"bc029fa94725104014953f288b5111db\") " pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120854     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-ca-certs\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120878     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-kubeconfig\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120900     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-usr-share-ca-certificates\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120923     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-certs\" (UniqueName: \"kubernetes.io/host-path/cf4141b3b06b4295e10fda6cee69dc09-etcd-certs\") pod \"etcd-clusterfuck-control-plane\" (UID: \"cf4141b3b06b4295e10fda6cee69dc09\") " pod="kube-system/etcd-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120947     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bc029fa94725104014953f288b5111db-usr-share-ca-certificates\") pod \"kube-apiserver-clusterfuck-control-plane\" (UID: \"bc029fa94725104014953f288b5111db\") " pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120964     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"flexvolume-dir\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-flexvolume-dir\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120984     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-usr-local-share-ca-certificates\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.121003     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-data\" (UniqueName: \"kubernetes.io/host-path/cf4141b3b06b4295e10fda6cee69dc09-etcd-data\") pod \"etcd-clusterfuck-control-plane\" (UID: \"cf4141b3b06b4295e10fda6cee69dc09\") " pod="kube-system/etcd-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.121024     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bc029fa94725104014953f288b5111db-usr-local-share-ca-certificates\") pod \"kube-apiserver-clusterfuck-control-plane\" (UID: \"bc029fa94725104014953f288b5111db\") " pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.709673     664 apiserver.go:52] "Watching apiserver"
Apr 14 12:19:05 clusterfuck-control-plane kubelet[664]: I0414 12:19:05.120145     664 desired_state_of_world_populator.go:159] "Finished populating initial desired state of world"
Apr 14 12:19:05 clusterfuck-control-plane kubelet[664]: I0414 12:19:05.129010     664 reconciler.go:41] "Reconciler: start to sync state"
Apr 14 12:19:05 clusterfuck-control-plane kubelet[664]: E0414 12:19:05.318621     664 kubelet.go:1802] "Failed creating a mirror pod for" err="pods \"kube-controller-manager-clusterfuck-control-plane\" already exists" pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:19:05 clusterfuck-control-plane kubelet[664]: E0414 12:19:05.510842     664 kubelet.go:1802] "Failed creating a mirror pod for" err="pods \"kube-apiserver-clusterfuck-control-plane\" already exists" pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:19:05 clusterfuck-control-plane kubelet[664]: E0414 12:19:05.720816     664 kubelet.go:1802] "Failed creating a mirror pod for" err="pods \"kube-scheduler-clusterfuck-control-plane\" already exists" pod="kube-system/kube-scheduler-clusterfuck-control-plane"
Apr 14 12:19:05 clusterfuck-control-plane kubelet[664]: I0414 12:19:05.910965     664 request.go:690] Waited for 1.012749919s due to client-side throttling, not priority and fairness, request: POST:https://clusterfuck-control-plane:6443/api/v1/namespaces/kube-system/pods
Apr 14 12:19:05 clusterfuck-control-plane kubelet[664]: E0414 12:19:05.927706     664 kubelet.go:1802] "Failed creating a mirror pod for" err="pods \"etcd-clusterfuck-control-plane\" already exists" pod="kube-system/etcd-clusterfuck-control-plane"
Apr 14 12:19:06 clusterfuck-control-plane kubelet[664]: I0414 12:19:06.713030     664 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-controller-manager-clusterfuck-control-plane" podStartSLOduration=2.712980526 pod.CreationTimestamp="2023-04-14 12:19:04 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-04-14 12:19:06.334976733 +0000 UTC m=+2.734902718" watchObservedRunningTime="2023-04-14 12:19:06.712980526 +0000 UTC m=+3.112906506"
Apr 14 12:19:07 clusterfuck-control-plane kubelet[664]: I0414 12:19:07.511481     664 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-apiserver-clusterfuck-control-plane" podStartSLOduration=4.511448493 pod.CreationTimestamp="2023-04-14 12:19:03 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-04-14 12:19:07.110909863 +0000 UTC m=+3.510835839" watchObservedRunningTime="2023-04-14 12:19:07.511448493 +0000 UTC m=+3.911374473"
Apr 14 12:19:07 clusterfuck-control-plane kubelet[664]: I0414 12:19:07.915308     664 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-scheduler-clusterfuck-control-plane" podStartSLOduration=4.915273761 pod.CreationTimestamp="2023-04-14 12:19:03 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-04-14 12:19:07.512220553 +0000 UTC m=+3.912146537" watchObservedRunningTime="2023-04-14 12:19:07.915273761 +0000 UTC m=+4.315199741"
Apr 14 12:19:08 clusterfuck-control-plane kubelet[664]: I0414 12:19:08.316658     664 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/etcd-clusterfuck-control-plane" podStartSLOduration=5.316627901 pod.CreationTimestamp="2023-04-14 12:19:03 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-04-14 12:19:07.915755466 +0000 UTC m=+4.315681440" watchObservedRunningTime="2023-04-14 12:19:08.316627901 +0000 UTC m=+4.716553881"
Apr 14 12:19:16 clusterfuck-control-plane kubelet[664]: I0414 12:19:16.886391     664 kuberuntime_manager.go:1114] "Updating runtime config through cri with podcidr" CIDR="10.244.0.0/24"
Apr 14 12:19:16 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:16.887261411Z" level=info msg="No cni config template is specified, wait for other system components to drop the config."
Apr 14 12:19:16 clusterfuck-control-plane kubelet[664]: I0414 12:19:16.887466     664 kubelet_network.go:61] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.244.0.0/24"
Apr 14 12:19:17 clusterfuck-control-plane kubelet[664]: I0414 12:19:17.649101     664 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:19:17 clusterfuck-control-plane kubelet[664]: I0414 12:19:17.651241     664 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:19:17 clusterfuck-control-plane systemd[1]: Created slice libcontainer container kubelet-kubepods-pod0e729414_c583_45f8_a7e3_e6794cf27101.slice.
Apr 14 12:19:17 clusterfuck-control-plane systemd[1]: Created slice libcontainer container kubelet-kubepods-besteffort-pod85b97808_cc7f_47bb_86ab_2e2c43ae00fc.slice.
Apr 14 12:19:17 clusterfuck-control-plane kubelet[664]: I0414 12:19:17.731873     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/85b97808-cc7f-47bb-86ab-2e2c43ae00fc-lib-modules\") pod \"kube-proxy-49nl7\" (UID: \"85b97808-cc7f-47bb-86ab-2e2c43ae00fc\") " pod="kube-system/kube-proxy-49nl7"
Apr 14 12:19:17 clusterfuck-control-plane kubelet[664]: I0414 12:19:17.731947     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/0e729414-c583-45f8-a7e3-e6794cf27101-xtables-lock\") pod \"kindnet-blcxg\" (UID: \"0e729414-c583-45f8-a7e3-e6794cf27101\") " pod="kube-system/kindnet-blcxg"
Apr 14 12:19:17 clusterfuck-control-plane kubelet[664]: I0414 12:19:17.731966     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/0e729414-c583-45f8-a7e3-e6794cf27101-lib-modules\") pod \"kindnet-blcxg\" (UID: \"0e729414-c583-45f8-a7e3-e6794cf27101\") " pod="kube-system/kindnet-blcxg"
Apr 14 12:19:17 clusterfuck-control-plane kubelet[664]: I0414 12:19:17.731983     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/85b97808-cc7f-47bb-86ab-2e2c43ae00fc-kube-proxy\") pod \"kube-proxy-49nl7\" (UID: \"85b97808-cc7f-47bb-86ab-2e2c43ae00fc\") " pod="kube-system/kube-proxy-49nl7"
Apr 14 12:19:17 clusterfuck-control-plane kubelet[664]: I0414 12:19:17.732003     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/85b97808-cc7f-47bb-86ab-2e2c43ae00fc-xtables-lock\") pod \"kube-proxy-49nl7\" (UID: \"85b97808-cc7f-47bb-86ab-2e2c43ae00fc\") " pod="kube-system/kube-proxy-49nl7"
Apr 14 12:19:17 clusterfuck-control-plane kubelet[664]: I0414 12:19:17.732020     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-r6hds\" (UniqueName: \"kubernetes.io/projected/85b97808-cc7f-47bb-86ab-2e2c43ae00fc-kube-api-access-r6hds\") pod \"kube-proxy-49nl7\" (UID: \"85b97808-cc7f-47bb-86ab-2e2c43ae00fc\") " pod="kube-system/kube-proxy-49nl7"
Apr 14 12:19:17 clusterfuck-control-plane kubelet[664]: I0414 12:19:17.732044     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cni-cfg\" (UniqueName: \"kubernetes.io/host-path/0e729414-c583-45f8-a7e3-e6794cf27101-cni-cfg\") pod \"kindnet-blcxg\" (UID: \"0e729414-c583-45f8-a7e3-e6794cf27101\") " pod="kube-system/kindnet-blcxg"
Apr 14 12:19:17 clusterfuck-control-plane kubelet[664]: I0414 12:19:17.732062     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-shcb9\" (UniqueName: \"kubernetes.io/projected/0e729414-c583-45f8-a7e3-e6794cf27101-kube-api-access-shcb9\") pod \"kindnet-blcxg\" (UID: \"0e729414-c583-45f8-a7e3-e6794cf27101\") " pod="kube-system/kindnet-blcxg"
Apr 14 12:19:17 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:17.962077865Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kindnet-blcxg,Uid:0e729414-c583-45f8-a7e3-e6794cf27101,Namespace:kube-system,Attempt:0,}"
Apr 14 12:19:17 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:17.971345458Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-proxy-49nl7,Uid:85b97808-cc7f-47bb-86ab-2e2c43ae00fc,Namespace:kube-system,Attempt:0,}"
Apr 14 12:19:17 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:17.988380619Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 14 12:19:17 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:17.988587641Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 14 12:19:17 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:17.988599791Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 14 12:19:17 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:17.991947181Z" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/88c101c2b4d9597aeb244f0d849255cac7b3096fe53709b079afee3bbd498e17 pid=759 runtime=io.containerd.runc.v2
Apr 14 12:19:18 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:18.002320533Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 14 12:19:18 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:18.002364449Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 14 12:19:18 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:18.002376268Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 14 12:19:18 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:18.002873540Z" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/1287a0f5a4f7a4a7b9ffd915c666a3195967daa6aa2b25e58f3eb6919c1f0ca1 pid=780 runtime=io.containerd.runc.v2
Apr 14 12:19:18 clusterfuck-control-plane systemd[1]: Started libcontainer container 88c101c2b4d9597aeb244f0d849255cac7b3096fe53709b079afee3bbd498e17.
Apr 14 12:19:18 clusterfuck-control-plane systemd[1]: Started libcontainer container 1287a0f5a4f7a4a7b9ffd915c666a3195967daa6aa2b25e58f3eb6919c1f0ca1.
Apr 14 12:19:18 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:18.065710191Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-proxy-49nl7,Uid:85b97808-cc7f-47bb-86ab-2e2c43ae00fc,Namespace:kube-system,Attempt:0,} returns sandbox id \"1287a0f5a4f7a4a7b9ffd915c666a3195967daa6aa2b25e58f3eb6919c1f0ca1\""
Apr 14 12:19:18 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:18.068656040Z" level=info msg="CreateContainer within sandbox \"1287a0f5a4f7a4a7b9ffd915c666a3195967daa6aa2b25e58f3eb6919c1f0ca1\" for container &ContainerMetadata{Name:kube-proxy,Attempt:0,}"
Apr 14 12:19:18 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:18.246817679Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kindnet-blcxg,Uid:0e729414-c583-45f8-a7e3-e6794cf27101,Namespace:kube-system,Attempt:0,} returns sandbox id \"88c101c2b4d9597aeb244f0d849255cac7b3096fe53709b079afee3bbd498e17\""
Apr 14 12:19:18 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:18.252892791Z" level=info msg="PullImage \"docker.io/kindest/kindnetd:v20230330-48f316cd@sha256:c19d6362a6a928139820761475a38c24c0cf84d507b9ddf414a078cf627497af\""
Apr 14 12:19:18 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:18.752342215Z" level=info msg="CreateContainer within sandbox \"1287a0f5a4f7a4a7b9ffd915c666a3195967daa6aa2b25e58f3eb6919c1f0ca1\" for &ContainerMetadata{Name:kube-proxy,Attempt:0,} returns container id \"2cea9f3dec6e506522170efa044fef288bda250b301a2e6290dca8f85f953da8\""
Apr 14 12:19:18 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:18.756097792Z" level=info msg="StartContainer for \"2cea9f3dec6e506522170efa044fef288bda250b301a2e6290dca8f85f953da8\""
Apr 14 12:19:18 clusterfuck-control-plane systemd[1]: Started libcontainer container 2cea9f3dec6e506522170efa044fef288bda250b301a2e6290dca8f85f953da8.
Apr 14 12:19:18 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:18.859251850Z" level=info msg="StartContainer for \"2cea9f3dec6e506522170efa044fef288bda250b301a2e6290dca8f85f953da8\" returns successfully"
Apr 14 12:19:19 clusterfuck-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount1661160745.mount: Deactivated successfully.
Apr 14 12:19:20 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:20.971907729Z" level=info msg="ImageCreate event &ImageCreate{Name:docker.io/kindest/kindnetd@sha256:c19d6362a6a928139820761475a38c24c0cf84d507b9ddf414a078cf627497af,Labels:map[string]string{io.cri-containerd.image: managed,},XXX_unrecognized:[],}"
Apr 14 12:19:20 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:20.975864613Z" level=info msg="ImageUpdate event &ImageUpdate{Name:sha256:a329ae3c2c52fe00e9c4eaf48b081cd184ee4bf9aea059e497f4965f0a8deedb,Labels:map[string]string{io.cri-containerd.image: managed,},XXX_unrecognized:[],}"
Apr 14 12:19:20 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:20.981351419Z" level=info msg="ImageUpdate event &ImageUpdate{Name:docker.io/kindest/kindnetd@sha256:c19d6362a6a928139820761475a38c24c0cf84d507b9ddf414a078cf627497af,Labels:map[string]string{io.cri-containerd.image: managed,},XXX_unrecognized:[],}"
Apr 14 12:19:20 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:20.982846857Z" level=info msg="PullImage \"docker.io/kindest/kindnetd:v20230330-48f316cd@sha256:c19d6362a6a928139820761475a38c24c0cf84d507b9ddf414a078cf627497af\" returns image reference \"sha256:a329ae3c2c52fe00e9c4eaf48b081cd184ee4bf9aea059e497f4965f0a8deedb\""
Apr 14 12:19:20 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:20.997420791Z" level=info msg="CreateContainer within sandbox \"88c101c2b4d9597aeb244f0d849255cac7b3096fe53709b079afee3bbd498e17\" for container &ContainerMetadata{Name:kindnet-cni,Attempt:0,}"
Apr 14 12:19:21 clusterfuck-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount3585395983.mount: Deactivated successfully.
Apr 14 12:19:21 clusterfuck-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount4177808434.mount: Deactivated successfully.
Apr 14 12:19:21 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:21.023627761Z" level=info msg="CreateContainer within sandbox \"88c101c2b4d9597aeb244f0d849255cac7b3096fe53709b079afee3bbd498e17\" for &ContainerMetadata{Name:kindnet-cni,Attempt:0,} returns container id \"e62ec477a1ec64dc87a92c745d055d96fa2d7ef29b41304df3d1623d73331dd6\""
Apr 14 12:19:21 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:21.026535286Z" level=info msg="StartContainer for \"e62ec477a1ec64dc87a92c745d055d96fa2d7ef29b41304df3d1623d73331dd6\""
Apr 14 12:19:21 clusterfuck-control-plane systemd[1]: Started libcontainer container e62ec477a1ec64dc87a92c745d055d96fa2d7ef29b41304df3d1623d73331dd6.
Apr 14 12:19:21 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:21.584600925Z" level=info msg="StartContainer for \"e62ec477a1ec64dc87a92c745d055d96fa2d7ef29b41304df3d1623d73331dd6\" returns successfully"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.004470     664 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-proxy-49nl7" podStartSLOduration=5.004382984 pod.CreationTimestamp="2023-04-14 12:19:17 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-04-14 12:19:18.956106134 +0000 UTC m=+15.355878986" watchObservedRunningTime="2023-04-14 12:19:22.004382984 +0000 UTC m=+18.404155839"
Apr 14 12:19:22 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:22.108567279Z" level=error msg="failed to reload cni configuration after receiving fs change event(\"/etc/cni/net.d/10-kindnet.conflist.temp\": WRITE)" error="cni config load failed: no network config found in /etc/cni/net.d: cni plugin not initialized: failed to load cni config"
Apr 14 12:19:22 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:22.109378707Z" level=error msg="failed to reload cni configuration after receiving fs change event(\"/etc/cni/net.d/10-kindnet.conflist.temp\": WRITE)" error="cni config load failed: no network config found in /etc/cni/net.d: cni plugin not initialized: failed to load cni config"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.203957     664 kubelet_node_status.go:493] "Fast updating node status as it just became ready"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.246620     664 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kindnet-blcxg" podStartSLOduration=-9.223372031608183e+09 pod.CreationTimestamp="2023-04-14 12:19:17 +0000 UTC" firstStartedPulling="2023-04-14 12:19:18.248321798 +0000 UTC m=+14.648094648" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-04-14 12:19:22.005344721 +0000 UTC m=+18.405117583" watchObservedRunningTime="2023-04-14 12:19:22.246592249 +0000 UTC m=+18.646365108"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.246840     664 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: W0414 12:19:22.250092     664 reflector.go:424] object-"kube-system"/"coredns": failed to list *v1.ConfigMap: configmaps "coredns" is forbidden: User "system:node:clusterfuck-control-plane" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'clusterfuck-control-plane' and this object
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: E0414 12:19:22.250640     664 reflector.go:140] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "coredns" is forbidden: User "system:node:clusterfuck-control-plane" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'clusterfuck-control-plane' and this object
Apr 14 12:19:22 clusterfuck-control-plane systemd[1]: Created slice libcontainer container kubelet-kubepods-burstable-pod2cccd300_ad54_43eb_a30e_7e46e0a5546f.slice.
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.280865     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-qdngf\" (UniqueName: \"kubernetes.io/projected/2cccd300-ad54-43eb-a30e-7e46e0a5546f-kube-api-access-qdngf\") pod \"coredns-787d4945fb-jt4g6\" (UID: \"2cccd300-ad54-43eb-a30e-7e46e0a5546f\") " pod="kube-system/coredns-787d4945fb-jt4g6"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.280982     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/2cccd300-ad54-43eb-a30e-7e46e0a5546f-config-volume\") pod \"coredns-787d4945fb-jt4g6\" (UID: \"2cccd300-ad54-43eb-a30e-7e46e0a5546f\") " pod="kube-system/coredns-787d4945fb-jt4g6"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.290403     664 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:19:22 clusterfuck-control-plane systemd[1]: Created slice libcontainer container kubelet-kubepods-burstable-pod1163697a_ed1d_465b_842a_e45b59a37413.slice.
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.308872     664 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:19:22 clusterfuck-control-plane systemd[1]: Created slice libcontainer container kubelet-kubepods-besteffort-podd88d469e_6d93_4bb0_8d5e_83f2e7dab652.slice.
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.381616     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-7z5sk\" (UniqueName: \"kubernetes.io/projected/d88d469e-6d93-4bb0-8d5e-83f2e7dab652-kube-api-access-7z5sk\") pod \"local-path-provisioner-75f5b54ffd-q6wb9\" (UID: \"d88d469e-6d93-4bb0-8d5e-83f2e7dab652\") " pod="local-path-storage/local-path-provisioner-75f5b54ffd-q6wb9"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.381667     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/1163697a-ed1d-465b-842a-e45b59a37413-config-volume\") pod \"coredns-787d4945fb-cgh87\" (UID: \"1163697a-ed1d-465b-842a-e45b59a37413\") " pod="kube-system/coredns-787d4945fb-cgh87"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.381697     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/d88d469e-6d93-4bb0-8d5e-83f2e7dab652-config-volume\") pod \"local-path-provisioner-75f5b54ffd-q6wb9\" (UID: \"d88d469e-6d93-4bb0-8d5e-83f2e7dab652\") " pod="local-path-storage/local-path-provisioner-75f5b54ffd-q6wb9"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.381809     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-fpmhr\" (UniqueName: \"kubernetes.io/projected/1163697a-ed1d-465b-842a-e45b59a37413-kube-api-access-fpmhr\") pod \"coredns-787d4945fb-cgh87\" (UID: \"1163697a-ed1d-465b-842a-e45b59a37413\") " pod="kube-system/coredns-787d4945fb-cgh87"
Apr 14 12:19:22 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:22.622272548Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:local-path-provisioner-75f5b54ffd-q6wb9,Uid:d88d469e-6d93-4bb0-8d5e-83f2e7dab652,Namespace:local-path-storage,Attempt:0,}"
Apr 14 12:19:22 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:22.698063448Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 14 12:19:22 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:22.698192560Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 14 12:19:22 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:22.698219801Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 14 12:19:22 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:22.699923966Z" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/1131ad6f26f61b33c7609ef55c440c1d37856423117b48bb2128d0d2730709f2 pid=1093 runtime=io.containerd.runc.v2
Apr 14 12:19:22 clusterfuck-control-plane systemd[1]: Started libcontainer container 1131ad6f26f61b33c7609ef55c440c1d37856423117b48bb2128d0d2730709f2.
Apr 14 12:19:23 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:23.052340173Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:local-path-provisioner-75f5b54ffd-q6wb9,Uid:d88d469e-6d93-4bb0-8d5e-83f2e7dab652,Namespace:local-path-storage,Attempt:0,} returns sandbox id \"1131ad6f26f61b33c7609ef55c440c1d37856423117b48bb2128d0d2730709f2\""
Apr 14 12:19:23 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:23.057118909Z" level=info msg="PullImage \"docker.io/kindest/local-path-provisioner:v0.0.23-kind.0@sha256:f2d0a02831ff3a03cf51343226670d5060623b43a4cfc4808bd0875b2c4b9501\""
Apr 14 12:19:23 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:23.184375346Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:coredns-787d4945fb-jt4g6,Uid:2cccd300-ad54-43eb-a30e-7e46e0a5546f,Namespace:kube-system,Attempt:0,}"
Apr 14 12:19:23 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:23.202118721Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:coredns-787d4945fb-cgh87,Uid:1163697a-ed1d-465b-842a-e45b59a37413,Namespace:kube-system,Attempt:0,}"
Apr 14 12:19:23 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:23.240534710Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 14 12:19:23 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:23.240600692Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 14 12:19:23 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:23.240612269Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 14 12:19:23 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:23.240828616Z" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/6690cd60900d951f619e37c180b3cd8a21d33691ffe6fe1f2425e5df1940bfcc pid=1172 runtime=io.containerd.runc.v2
Apr 14 12:19:23 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:23.255368249Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 14 12:19:23 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:23.255674846Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 14 12:19:23 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:23.255916493Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 14 12:19:23 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:23.256170781Z" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/cc83e9adbf730d9538a1bf4a4cc4fecf35c72f86cf0278726cbdaa857b31156d pid=1202 runtime=io.containerd.runc.v2
Apr 14 12:19:23 clusterfuck-control-plane systemd[1]: Started libcontainer container 6690cd60900d951f619e37c180b3cd8a21d33691ffe6fe1f2425e5df1940bfcc.
Apr 14 12:19:23 clusterfuck-control-plane systemd[1]: Started libcontainer container cc83e9adbf730d9538a1bf4a4cc4fecf35c72f86cf0278726cbdaa857b31156d.
Apr 14 12:19:23 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:23.333023932Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:coredns-787d4945fb-jt4g6,Uid:2cccd300-ad54-43eb-a30e-7e46e0a5546f,Namespace:kube-system,Attempt:0,} returns sandbox id \"6690cd60900d951f619e37c180b3cd8a21d33691ffe6fe1f2425e5df1940bfcc\""
Apr 14 12:19:23 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:23.336979397Z" level=info msg="CreateContainer within sandbox \"6690cd60900d951f619e37c180b3cd8a21d33691ffe6fe1f2425e5df1940bfcc\" for container &ContainerMetadata{Name:coredns,Attempt:0,}"
Apr 14 12:19:23 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:23.364273497Z" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:coredns-787d4945fb-cgh87,Uid:1163697a-ed1d-465b-842a-e45b59a37413,Namespace:kube-system,Attempt:0,} returns sandbox id \"cc83e9adbf730d9538a1bf4a4cc4fecf35c72f86cf0278726cbdaa857b31156d\""
Apr 14 12:19:23 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:23.369461301Z" level=info msg="CreateContainer within sandbox \"cc83e9adbf730d9538a1bf4a4cc4fecf35c72f86cf0278726cbdaa857b31156d\" for container &ContainerMetadata{Name:coredns,Attempt:0,}"
Apr 14 12:19:24 clusterfuck-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount3906783268.mount: Deactivated successfully.
Apr 14 12:19:25 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:25.109954863Z" level=info msg="CreateContainer within sandbox \"cc83e9adbf730d9538a1bf4a4cc4fecf35c72f86cf0278726cbdaa857b31156d\" for &ContainerMetadata{Name:coredns,Attempt:0,} returns container id \"238cde4af934f5a084c465d96d66acabdcafebc0358edc71fe7dd7420b8ee31f\""
Apr 14 12:19:25 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:25.111803497Z" level=info msg="StartContainer for \"238cde4af934f5a084c465d96d66acabdcafebc0358edc71fe7dd7420b8ee31f\""
Apr 14 12:19:25 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:25.131571980Z" level=info msg="CreateContainer within sandbox \"6690cd60900d951f619e37c180b3cd8a21d33691ffe6fe1f2425e5df1940bfcc\" for &ContainerMetadata{Name:coredns,Attempt:0,} returns container id \"33986cc235537d73fea9eea05f098b903de00f4efa42e08a5c4c0b8d2e6f5fac\""
Apr 14 12:19:25 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:25.133266687Z" level=info msg="StartContainer for \"33986cc235537d73fea9eea05f098b903de00f4efa42e08a5c4c0b8d2e6f5fac\""
Apr 14 12:19:25 clusterfuck-control-plane systemd[1]: Started libcontainer container 238cde4af934f5a084c465d96d66acabdcafebc0358edc71fe7dd7420b8ee31f.
Apr 14 12:19:25 clusterfuck-control-plane systemd[1]: Started libcontainer container 33986cc235537d73fea9eea05f098b903de00f4efa42e08a5c4c0b8d2e6f5fac.
Apr 14 12:19:25 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:25.286565685Z" level=info msg="StartContainer for \"238cde4af934f5a084c465d96d66acabdcafebc0358edc71fe7dd7420b8ee31f\" returns successfully"
Apr 14 12:19:25 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:25.328329768Z" level=info msg="StartContainer for \"33986cc235537d73fea9eea05f098b903de00f4efa42e08a5c4c0b8d2e6f5fac\" returns successfully"
Apr 14 12:19:26 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:26.566078434Z" level=info msg="ImageCreate event &ImageCreate{Name:docker.io/kindest/local-path-provisioner@sha256:f2d0a02831ff3a03cf51343226670d5060623b43a4cfc4808bd0875b2c4b9501,Labels:map[string]string{io.cri-containerd.image: managed,},XXX_unrecognized:[],}"
Apr 14 12:19:26 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:26.571327861Z" level=info msg="ImageUpdate event &ImageUpdate{Name:sha256:c408b2276bb76627a6f633bf0d26052c208ebd51681c6c89866cc9647471c0bc,Labels:map[string]string{io.cri-containerd.image: managed,},XXX_unrecognized:[],}"
Apr 14 12:19:26 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:26.574147454Z" level=info msg="ImageUpdate event &ImageUpdate{Name:docker.io/kindest/local-path-provisioner@sha256:f2d0a02831ff3a03cf51343226670d5060623b43a4cfc4808bd0875b2c4b9501,Labels:map[string]string{io.cri-containerd.image: managed,},XXX_unrecognized:[],}"
Apr 14 12:19:26 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:26.574825867Z" level=info msg="PullImage \"docker.io/kindest/local-path-provisioner:v0.0.23-kind.0@sha256:f2d0a02831ff3a03cf51343226670d5060623b43a4cfc4808bd0875b2c4b9501\" returns image reference \"sha256:c408b2276bb76627a6f633bf0d26052c208ebd51681c6c89866cc9647471c0bc\""
Apr 14 12:19:26 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:26.577576562Z" level=info msg="CreateContainer within sandbox \"1131ad6f26f61b33c7609ef55c440c1d37856423117b48bb2128d0d2730709f2\" for container &ContainerMetadata{Name:local-path-provisioner,Attempt:0,}"
Apr 14 12:19:26 clusterfuck-control-plane systemd[1]: var-lib-containerd-tmpmounts-containerd\x2dmount1306895056.mount: Deactivated successfully.
Apr 14 12:19:26 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:26.600592453Z" level=info msg="CreateContainer within sandbox \"1131ad6f26f61b33c7609ef55c440c1d37856423117b48bb2128d0d2730709f2\" for &ContainerMetadata{Name:local-path-provisioner,Attempt:0,} returns container id \"49cfbec26b20ca55bd4cadbeb70bc4cc8bdbdaf53c14b953c29d4a878cae863b\""
Apr 14 12:19:26 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:26.601546588Z" level=info msg="StartContainer for \"49cfbec26b20ca55bd4cadbeb70bc4cc8bdbdaf53c14b953c29d4a878cae863b\""
Apr 14 12:19:26 clusterfuck-control-plane systemd[1]: Started libcontainer container 49cfbec26b20ca55bd4cadbeb70bc4cc8bdbdaf53c14b953c29d4a878cae863b.
Apr 14 12:19:26 clusterfuck-control-plane kubelet[664]: I0414 12:19:26.686197     664 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/coredns-787d4945fb-cgh87" podStartSLOduration=9.686159933999999 pod.CreationTimestamp="2023-04-14 12:19:17 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-04-14 12:19:26.615838287 +0000 UTC m=+23.015611148" watchObservedRunningTime="2023-04-14 12:19:26.686159934 +0000 UTC m=+23.085932797"
Apr 14 12:19:26 clusterfuck-control-plane kubelet[664]: I0414 12:19:26.805210     664 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/coredns-787d4945fb-jt4g6" podStartSLOduration=9.805174324 pod.CreationTimestamp="2023-04-14 12:19:17 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-04-14 12:19:26.7301764 +0000 UTC m=+23.129949262" watchObservedRunningTime="2023-04-14 12:19:26.805174324 +0000 UTC m=+23.204947178"
Apr 14 12:19:26 clusterfuck-control-plane containerd[101]: time="2023-04-14T12:19:26.964703008Z" level=info msg="StartContainer for \"49cfbec26b20ca55bd4cadbeb70bc4cc8bdbdaf53c14b953c29d4a878cae863b\" returns successfully"
Apr 14 12:19:27 clusterfuck-control-plane kubelet[664]: I0414 12:19:27.041572     664 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="local-path-storage/local-path-provisioner-75f5b54ffd-q6wb9" podStartSLOduration=-9.2233720268133e+09 pod.CreationTimestamp="2023-04-14 12:19:17 +0000 UTC" firstStartedPulling="2023-04-14 12:19:23.055198625 +0000 UTC m=+19.454971477" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-04-14 12:19:27.041209169 +0000 UTC m=+23.440982023" watchObservedRunningTime="2023-04-14 12:19:27.041476133 +0000 UTC m=+23.441248995"
Apr 14 12:19:53 clusterfuck-control-plane systemd[1]: Starting Cleanup of Temporary Directories...
Apr 14 12:19:53 clusterfuck-control-plane systemd[1]: systemd-tmpfiles-clean.service: Deactivated successfully.
Apr 14 12:19:53 clusterfuck-control-plane systemd[1]: Finished Cleanup of Temporary Directories.
Apr 14 12:24:03 clusterfuck-control-plane kubelet[664]: W0414 12:24:03.880035     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:29:03 clusterfuck-control-plane kubelet[664]: W0414 12:29:03.878092     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:34:03 clusterfuck-control-plane kubelet[664]: W0414 12:34:03.876302     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:39:03 clusterfuck-control-plane kubelet[664]: W0414 12:39:03.870126     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:44:03 clusterfuck-control-plane kubelet[664]: W0414 12:44:03.866942     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:49:03 clusterfuck-control-plane kubelet[664]: W0414 12:49:03.864911     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:54:03 clusterfuck-control-plane kubelet[664]: W0414 12:54:03.862520     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:59:03 clusterfuck-control-plane kubelet[664]: W0414 12:59:03.861440     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:04:03 clusterfuck-control-plane kubelet[664]: W0414 13:04:03.859073     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:09:03 clusterfuck-control-plane kubelet[664]: W0414 13:09:03.861692     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:14:03 clusterfuck-control-plane kubelet[664]: W0414 13:14:03.829853     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:19:03 clusterfuck-control-plane kubelet[664]: W0414 13:19:03.823994     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:24:03 clusterfuck-control-plane kubelet[664]: W0414 13:24:03.821036     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:29:03 clusterfuck-control-plane kubelet[664]: W0414 13:29:03.816550     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:34:03 clusterfuck-control-plane kubelet[664]: W0414 13:34:03.806506     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:39:03 clusterfuck-control-plane kubelet[664]: W0414 13:39:03.802006     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:44:03 clusterfuck-control-plane kubelet[664]: W0414 13:44:03.796944     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
