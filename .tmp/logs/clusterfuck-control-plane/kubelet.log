Apr 14 12:18:38 clusterfuck-control-plane systemd[1]: Condition check resulted in kubelet: The Kubernetes Node Agent being skipped.
Apr 14 12:18:47 clusterfuck-control-plane systemd[1]: Starting kubelet: The Kubernetes Node Agent...
Apr 14 12:18:47 clusterfuck-control-plane systemd[1]: Started kubelet: The Kubernetes Node Agent.
Apr 14 12:18:47 clusterfuck-control-plane kubelet[168]: Flag --pod-infra-container-image has been deprecated, will be removed in 1.27. Image garbage collector will get sandbox image information from CRI.
Apr 14 12:18:47 clusterfuck-control-plane kubelet[168]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:47 clusterfuck-control-plane kubelet[168]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:47 clusterfuck-control-plane kubelet[168]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:47 clusterfuck-control-plane kubelet[168]: I0414 12:18:47.831653     168 server.go:198] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
Apr 14 12:18:47 clusterfuck-control-plane kubelet[168]: Flag --pod-infra-container-image has been deprecated, will be removed in 1.27. Image garbage collector will get sandbox image information from CRI.
Apr 14 12:18:47 clusterfuck-control-plane kubelet[168]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:47 clusterfuck-control-plane kubelet[168]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:47 clusterfuck-control-plane kubelet[168]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.100589     168 server.go:412] "Kubelet version" kubeletVersion="v1.26.3"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.100741     168 server.go:414] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.101116     168 server.go:836] "Client rotation is on, will bootstrap in background"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.106603     168 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/ca.crt"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: E0414 12:18:48.107478     168 certificate_manager.go:471] kubernetes.io/kube-apiserver-client-kubelet: Failed while requesting a signed certificate from the control plane: cannot create certificate signing request: Post "https://clusterfuck-control-plane:6443/apis/certificates.k8s.io/v1/certificatesigningrequests": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: W0414 12:18:48.109779     168 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.111517     168 container_manager_linux.go:267] "Container manager verified user specified cgroup-root exists" cgroupRoot=[kubelet]
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.111617     168 container_manager_linux.go:272] "Creating Container Manager object based on Node Config" nodeConfig={RuntimeCgroupsName: SystemCgroupsName: KubeletCgroupsName: KubeletOOMScoreAdj:-999 ContainerRuntime: CgroupsPerQOS:true CgroupRoot:/kubelet CgroupDriver:systemd KubeletRootDir:/var/lib/kubelet ProtectKernelDefaults:false NodeAllocatableConfig:{KubeReservedCgroupName: SystemReservedCgroupName: ReservedSystemCPUs: EnforceNodeAllocatable:map[pods:{}] KubeReserved:map[] SystemReserved:map[] HardEvictionThresholds:[]} QOSReserved:map[] CPUManagerPolicy:none CPUManagerPolicyOptions:map[] ExperimentalTopologyManagerScope:container CPUManagerReconcilePeriod:10s ExperimentalMemoryManagerPolicy:None ExperimentalMemoryManagerReservedMemory:[] ExperimentalPodPidsLimit:-1 EnforceCPULimits:true CPUCFSQuotaPeriod:100ms ExperimentalTopologyManagerPolicy:none ExperimentalTopologyManagerPolicyOptions:map[]}
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.111639     168 topology_manager.go:134] "Creating topology manager with policy per scope" topologyPolicyName="none" topologyScopeName="container"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.111654     168 container_manager_linux.go:308] "Creating device plugin manager"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.111780     168 state_mem.go:36] "Initialized new in-memory state store"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.118145     168 kubelet.go:398] "Attempting to sync node with API server"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.118213     168 kubelet.go:286] "Adding static pod path" path="/etc/kubernetes/manifests"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.118238     168 kubelet.go:297] "Adding apiserver pod source"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.118259     168 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.120617     168 kuberuntime_manager.go:244] "Container runtime initialized" containerRuntime="containerd" version="v1.6.19-46-g941215f49" apiVersion="v1"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: W0414 12:18:48.120873     168 probe.go:268] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.121292     168 server.go:1186] "Started kubelet"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.122736     168 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.126662     168 server.go:161] "Starting to listen" address="0.0.0.0" port=10250
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: W0414 12:18:48.127427     168 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://clusterfuck-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dclusterfuck-control-plane&limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: E0414 12:18:48.127503     168 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://clusterfuck-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dclusterfuck-control-plane&limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: W0414 12:18:48.127581     168 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://clusterfuck-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: E0414 12:18:48.127647     168 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://clusterfuck-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.128303     168 volume_manager.go:293] "Starting Kubelet Volume Manager"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.128618     168 desired_state_of_world_populator.go:151] "Desired state populator starts to run"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.130993     168 server.go:451] "Adding debug handlers to kubelet server"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: W0414 12:18:48.134686     168 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: Get "https://clusterfuck-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: E0414 12:18:48.134763     168 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://clusterfuck-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: E0414 12:18:48.138181     168 event.go:276] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b3c76f995", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 48, 121268629, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 48, 121268629, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://clusterfuck-control-plane:6443/api/v1/namespaces/default/events": dial tcp 172.21.0.5:6443: connect: connection refused'(may retry after sleeping)
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: E0414 12:18:48.150165     168 controller.go:146] failed to ensure lease exists, will retry in 200ms, error: Get "https://clusterfuck-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/clusterfuck-control-plane?timeout=10s": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.158190     168 cpu_manager.go:214] "Starting CPU manager" policy="none"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.158242     168 cpu_manager.go:215] "Reconciling" reconcilePeriod="10s"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.158260     168 state_mem.go:36] "Initialized new in-memory state store"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.161669     168 policy_none.go:49] "None policy: Start"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.162889     168 memory_manager.go:169] "Starting memorymanager" policy="None"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.162943     168 state_mem.go:35] "Initializing new in-memory state store"
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: I0414 12:18:48.193412     168 kubelet_network_linux.go:63] "Initialized iptables rules." protocol=IPv4
Apr 14 12:18:48 clusterfuck-control-plane kubelet[168]: E0414 12:18:48.193810     168 kubelet.go:1466] "Failed to start ContainerManager" err="failed to initialize top level QOS containers: root container [kubelet kubepods] doesn't exist"
Apr 14 12:18:48 clusterfuck-control-plane systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Apr 14 12:18:48 clusterfuck-control-plane systemd[1]: kubelet.service: Failed with result 'exit-code'.
Apr 14 12:18:49 clusterfuck-control-plane systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 1.
Apr 14 12:18:49 clusterfuck-control-plane systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Apr 14 12:18:49 clusterfuck-control-plane systemd[1]: Starting kubelet: The Kubernetes Node Agent...
Apr 14 12:18:49 clusterfuck-control-plane systemd[1]: Started kubelet: The Kubernetes Node Agent.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: Flag --pod-infra-container-image has been deprecated, will be removed in 1.27. Image garbage collector will get sandbox image information from CRI.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.387800     217 server.go:198] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: Flag --pod-infra-container-image has been deprecated, will be removed in 1.27. Image garbage collector will get sandbox image information from CRI.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.392559     217 server.go:412] "Kubelet version" kubeletVersion="v1.26.3"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.392616     217 server.go:414] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.392898     217 server.go:836] "Client rotation is on, will bootstrap in background"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.394333     217 certificate_store.go:130] Loading cert/key pair from "/var/lib/kubelet/pki/kubelet-client-current.pem".
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: W0414 12:18:49.396807     217 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.398180     217 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/ca.crt"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.398549     217 container_manager_linux.go:267] "Container manager verified user specified cgroup-root exists" cgroupRoot=[kubelet]
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.398702     217 container_manager_linux.go:272] "Creating Container Manager object based on Node Config" nodeConfig={RuntimeCgroupsName: SystemCgroupsName: KubeletCgroupsName: KubeletOOMScoreAdj:-999 ContainerRuntime: CgroupsPerQOS:true CgroupRoot:/kubelet CgroupDriver:systemd KubeletRootDir:/var/lib/kubelet ProtectKernelDefaults:false NodeAllocatableConfig:{KubeReservedCgroupName: SystemReservedCgroupName: ReservedSystemCPUs: EnforceNodeAllocatable:map[pods:{}] KubeReserved:map[] SystemReserved:map[] HardEvictionThresholds:[]} QOSReserved:map[] CPUManagerPolicy:none CPUManagerPolicyOptions:map[] ExperimentalTopologyManagerScope:container CPUManagerReconcilePeriod:10s ExperimentalMemoryManagerPolicy:None ExperimentalMemoryManagerReservedMemory:[] ExperimentalPodPidsLimit:-1 EnforceCPULimits:true CPUCFSQuotaPeriod:100ms ExperimentalTopologyManagerPolicy:none ExperimentalTopologyManagerPolicyOptions:map[]}
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.398856     217 topology_manager.go:134] "Creating topology manager with policy per scope" topologyPolicyName="none" topologyScopeName="container"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.398965     217 container_manager_linux.go:308] "Creating device plugin manager"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.399029     217 state_mem.go:36] "Initialized new in-memory state store"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.406667     217 kubelet.go:398] "Attempting to sync node with API server"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.406721     217 kubelet.go:286] "Adding static pod path" path="/etc/kubernetes/manifests"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.406745     217 kubelet.go:297] "Adding apiserver pod source"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.406759     217 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.408157     217 kuberuntime_manager.go:244] "Container runtime initialized" containerRuntime="containerd" version="v1.6.19-46-g941215f49" apiVersion="v1"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.408674     217 server.go:1186] "Started kubelet"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.410939     217 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: W0414 12:18:49.413722     217 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://clusterfuck-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dclusterfuck-control-plane&limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.414055     217 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://clusterfuck-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dclusterfuck-control-plane&limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: W0414 12:18:49.414410     217 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://clusterfuck-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.414509     217 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://clusterfuck-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.415112     217 server.go:161] "Starting to listen" address="0.0.0.0" port=10250
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.416364     217 server.go:451] "Adding debug handlers to kubelet server"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.420527     217 volume_manager.go:293] "Starting Kubelet Volume Manager"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.420696     217 desired_state_of_world_populator.go:151] "Desired state populator starts to run"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: W0414 12:18:49.423866     217 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: Get "https://clusterfuck-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.423928     217 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://clusterfuck-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.424902     217 event.go:276] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b89326475", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 408619637, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 408619637, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://clusterfuck-control-plane:6443/api/v1/namespaces/default/events": dial tcp 172.21.0.5:6443: connect: connection refused'(may retry after sleeping)
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.438738     217 controller.go:146] failed to ensure lease exists, will retry in 200ms, error: Get "https://clusterfuck-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/clusterfuck-control-plane?timeout=10s": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.447882     217 cpu_manager.go:214] "Starting CPU manager" policy="none"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.447932     217 cpu_manager.go:215] "Reconciling" reconcilePeriod="10s"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.447951     217 state_mem.go:36] "Initialized new in-memory state store"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.448087     217 state_mem.go:88] "Updated default CPUSet" cpuSet=""
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.448099     217 state_mem.go:96] "Updated CPUSet assignments" assignments=map[]
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.448104     217 policy_none.go:49] "None policy: Start"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.449152     217 memory_manager.go:169] "Starting memorymanager" policy="None"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.449244     217 state_mem.go:35] "Initializing new in-memory state store"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.449409     217 state_mem.go:75] "Updated machine memory state"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.478172     217 manager.go:455] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.478504     217 plugin_manager.go:118] "Starting Kubelet Plugin Manager"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.479977     217 eviction_manager.go:261] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"clusterfuck-control-plane\" not found"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.481615     217 kubelet_network_linux.go:63] "Initialized iptables rules." protocol=IPv4
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.518014     217 kubelet_network_linux.go:63] "Initialized iptables rules." protocol=IPv6
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.518143     217 status_manager.go:176] "Starting to sync pod status with apiserver"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.518386     217 kubelet.go:2113] "Starting kubelet main sync loop"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.518491     217 kubelet.go:2137] "Skipping pod synchronization" err="PLEG is not healthy: pleg has yet to be successful"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: W0414 12:18:49.519913     217 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.RuntimeClass: Get "https://clusterfuck-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.520047     217 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://clusterfuck-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.522108     217 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.522624     217 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://clusterfuck-control-plane:6443/api/v1/nodes\": dial tcp 172.21.0.5:6443: connect: connection refused" node="clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.618871     217 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.620043     217 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.620663     217 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.621479     217 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.621899     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/bc029fa94725104014953f288b5111db-ca-certs\") pod \"kube-apiserver-clusterfuck-control-plane\" (UID: \"bc029fa94725104014953f288b5111db\") " pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.621994     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bc029fa94725104014953f288b5111db-etc-ca-certificates\") pod \"kube-apiserver-clusterfuck-control-plane\" (UID: \"bc029fa94725104014953f288b5111db\") " pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.622100     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bc029fa94725104014953f288b5111db-usr-local-share-ca-certificates\") pod \"kube-apiserver-clusterfuck-control-plane\" (UID: \"bc029fa94725104014953f288b5111db\") " pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.622163     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bc029fa94725104014953f288b5111db-usr-share-ca-certificates\") pod \"kube-apiserver-clusterfuck-control-plane\" (UID: \"bc029fa94725104014953f288b5111db\") " pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.622273     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-certs\" (UniqueName: \"kubernetes.io/host-path/cf4141b3b06b4295e10fda6cee69dc09-etcd-certs\") pod \"etcd-clusterfuck-control-plane\" (UID: \"cf4141b3b06b4295e10fda6cee69dc09\") " pod="kube-system/etcd-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.622419     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/bc029fa94725104014953f288b5111db-k8s-certs\") pod \"kube-apiserver-clusterfuck-control-plane\" (UID: \"bc029fa94725104014953f288b5111db\") " pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.622503     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-usr-local-share-ca-certificates\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.622676     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-usr-share-ca-certificates\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.622755     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-data\" (UniqueName: \"kubernetes.io/host-path/cf4141b3b06b4295e10fda6cee69dc09-etcd-data\") pod \"etcd-clusterfuck-control-plane\" (UID: \"cf4141b3b06b4295e10fda6cee69dc09\") " pod="kube-system/etcd-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.622890     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-ca-certs\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.622980     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-etc-ca-certificates\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.623069     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"flexvolume-dir\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-flexvolume-dir\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.623129     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-k8s-certs\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.623203     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-kubeconfig\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.623158     217 status_manager.go:698] "Failed to get status for pod" podUID=bc029fa94725104014953f288b5111db pod="kube-system/kube-apiserver-clusterfuck-control-plane" err="Get \"https://clusterfuck-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-clusterfuck-control-plane\": dial tcp 172.21.0.5:6443: connect: connection refused"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.624142     217 status_manager.go:698] "Failed to get status for pod" podUID=cf4141b3b06b4295e10fda6cee69dc09 pod="kube-system/etcd-clusterfuck-control-plane" err="Get \"https://clusterfuck-control-plane:6443/api/v1/namespaces/kube-system/pods/etcd-clusterfuck-control-plane\": dial tcp 172.21.0.5:6443: connect: connection refused"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.631834     217 status_manager.go:698] "Failed to get status for pod" podUID=ba2bfe9fab65c7374db97567e0331986 pod="kube-system/kube-controller-manager-clusterfuck-control-plane" err="Get \"https://clusterfuck-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-clusterfuck-control-plane\": dial tcp 172.21.0.5:6443: connect: connection refused"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.632290     217 status_manager.go:698] "Failed to get status for pod" podUID=52a49c1dda96443061d997ca66c5aae7 pod="kube-system/kube-scheduler-clusterfuck-control-plane" err="Get \"https://clusterfuck-control-plane:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-clusterfuck-control-plane\": dial tcp 172.21.0.5:6443: connect: connection refused"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.640538     217 controller.go:146] failed to ensure lease exists, will retry in 400ms, error: Get "https://clusterfuck-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/clusterfuck-control-plane?timeout=10s": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.723403     217 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/52a49c1dda96443061d997ca66c5aae7-kubeconfig\") pod \"kube-scheduler-clusterfuck-control-plane\" (UID: \"52a49c1dda96443061d997ca66c5aae7\") " pod="kube-system/kube-scheduler-clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: I0414 12:18:49.723800     217 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-control-plane"
Apr 14 12:18:49 clusterfuck-control-plane kubelet[217]: E0414 12:18:49.724414     217 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://clusterfuck-control-plane:6443/api/v1/nodes\": dial tcp 172.21.0.5:6443: connect: connection refused" node="clusterfuck-control-plane"
Apr 14 12:18:50 clusterfuck-control-plane kubelet[217]: E0414 12:18:50.041953     217 controller.go:146] failed to ensure lease exists, will retry in 800ms, error: Get "https://clusterfuck-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/clusterfuck-control-plane?timeout=10s": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:50 clusterfuck-control-plane kubelet[217]: I0414 12:18:50.126197     217 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-control-plane"
Apr 14 12:18:50 clusterfuck-control-plane kubelet[217]: E0414 12:18:50.126702     217 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://clusterfuck-control-plane:6443/api/v1/nodes\": dial tcp 172.21.0.5:6443: connect: connection refused" node="clusterfuck-control-plane"
Apr 14 12:18:50 clusterfuck-control-plane kubelet[217]: W0414 12:18:50.423429     217 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://clusterfuck-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dclusterfuck-control-plane&limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:50 clusterfuck-control-plane kubelet[217]: E0414 12:18:50.423489     217 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://clusterfuck-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dclusterfuck-control-plane&limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:50 clusterfuck-control-plane kubelet[217]: W0414 12:18:50.677936     217 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: Get "https://clusterfuck-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:50 clusterfuck-control-plane kubelet[217]: E0414 12:18:50.678018     217 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://clusterfuck-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:50 clusterfuck-control-plane kubelet[217]: W0414 12:18:50.678074     217 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://clusterfuck-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:50 clusterfuck-control-plane kubelet[217]: E0414 12:18:50.678113     217 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://clusterfuck-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:50 clusterfuck-control-plane kubelet[217]: E0414 12:18:50.844237     217 controller.go:146] failed to ensure lease exists, will retry in 1.6s, error: Get "https://clusterfuck-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/clusterfuck-control-plane?timeout=10s": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:51 clusterfuck-control-plane kubelet[217]: I0414 12:18:51.042999     217 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-control-plane"
Apr 14 12:18:51 clusterfuck-control-plane kubelet[217]: E0414 12:18:51.043417     217 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://clusterfuck-control-plane:6443/api/v1/nodes\": dial tcp 172.21.0.5:6443: connect: connection refused" node="clusterfuck-control-plane"
Apr 14 12:18:51 clusterfuck-control-plane kubelet[217]: W0414 12:18:51.113020     217 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.RuntimeClass: Get "https://clusterfuck-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:51 clusterfuck-control-plane kubelet[217]: E0414 12:18:51.113068     217 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://clusterfuck-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:52 clusterfuck-control-plane kubelet[217]: W0414 12:18:52.094690     217 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://clusterfuck-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dclusterfuck-control-plane&limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:52 clusterfuck-control-plane kubelet[217]: E0414 12:18:52.094740     217 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://clusterfuck-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dclusterfuck-control-plane&limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:52 clusterfuck-control-plane kubelet[217]: E0414 12:18:52.445846     217 controller.go:146] failed to ensure lease exists, will retry in 3.2s, error: Get "https://clusterfuck-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/clusterfuck-control-plane?timeout=10s": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:52 clusterfuck-control-plane kubelet[217]: I0414 12:18:52.654604     217 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-control-plane"
Apr 14 12:18:52 clusterfuck-control-plane kubelet[217]: E0414 12:18:52.655265     217 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://clusterfuck-control-plane:6443/api/v1/nodes\": dial tcp 172.21.0.5:6443: connect: connection refused" node="clusterfuck-control-plane"
Apr 14 12:18:52 clusterfuck-control-plane kubelet[217]: W0414 12:18:52.719784     217 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://clusterfuck-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:52 clusterfuck-control-plane kubelet[217]: E0414 12:18:52.720112     217 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://clusterfuck-control-plane:6443/api/v1/services?limit=500&resourceVersion=0": dial tcp 172.21.0.5:6443: connect: connection refused
Apr 14 12:18:55 clusterfuck-control-plane kubelet[217]: I0414 12:18:55.856342     217 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-control-plane"
Apr 14 12:18:59 clusterfuck-control-plane kubelet[217]: E0414 12:18:59.480901     217 eviction_manager.go:261] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"clusterfuck-control-plane\" not found"
Apr 14 12:19:00 clusterfuck-control-plane kubelet[217]: E0414 12:19:00.684914     217 nodelease.go:49] "Failed to get node when trying to set owner ref to the node lease" err="nodes \"clusterfuck-control-plane\" not found" node="clusterfuck-control-plane"
Apr 14 12:19:00 clusterfuck-control-plane kubelet[217]: I0414 12:19:00.822073     217 kubelet_node_status.go:73] "Successfully registered node" node="clusterfuck-control-plane"
Apr 14 12:19:00 clusterfuck-control-plane kubelet[217]: E0414 12:19:00.844268     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b89326475", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 408619637, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 408619637, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:00 clusterfuck-control-plane kubelet[217]: E0414 12:19:00.903613     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b8b6e141b", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node clusterfuck-control-plane status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446085659, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446085659, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:00 clusterfuck-control-plane kubelet[217]: E0414 12:19:00.964495     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b8b6e3499", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node clusterfuck-control-plane status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446093977, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446093977, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: E0414 12:19:01.020478     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b8b6e4287", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node clusterfuck-control-plane status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446097543, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446097543, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: E0414 12:19:01.074347     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b8d6e7d87", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeAllocatableEnforced", Message:"Updated Node Allocatable limit across pods", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 479667079, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 479667079, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: E0414 12:19:01.130609     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b8b6e141b", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node clusterfuck-control-plane status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446085659, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 522076233, time.Local), Count:2, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: E0414 12:19:01.186724     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b8b6e3499", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node clusterfuck-control-plane status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446093977, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 522081246, time.Local), Count:2, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: E0414 12:19:01.243510     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b8b6e4287", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node clusterfuck-control-plane status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446097543, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 522085610, time.Local), Count:2, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: E0414 12:19:01.301083     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b8b6e141b", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node clusterfuck-control-plane status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446085659, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 619965180, time.Local), Count:3, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: I0414 12:19:01.427629     217 apiserver.go:52] "Watching apiserver"
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: I0414 12:19:01.520864     217 desired_state_of_world_populator.go:159] "Finished populating initial desired state of world"
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: I0414 12:19:01.547631     217 reconciler.go:41] "Reconciler: start to sync state"
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: E0414 12:19:01.596275     217 kubelet.go:1802] "Failed creating a mirror pod for" err="pods \"kube-controller-manager-clusterfuck-control-plane\" is forbidden: no PriorityClass with name system-node-critical was found" pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:19:01 clusterfuck-control-plane kubelet[217]: E0414 12:19:01.698124     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b8b6e3499", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node clusterfuck-control-plane status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446093977, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 619974204, time.Local), Count:3, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:02 clusterfuck-control-plane kubelet[217]: E0414 12:19:02.100421     217 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"clusterfuck-control-plane.1755cc5b8b6e4287", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"clusterfuck-control-plane", UID:"clusterfuck-control-plane", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node clusterfuck-control-plane status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"clusterfuck-control-plane"}, FirstTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 446097543, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 12, 18, 49, 619977492, time.Local), Count:3, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'namespaces "default" not found' (will not retry!)
Apr 14 12:19:03 clusterfuck-control-plane systemd[1]: Stopping kubelet: The Kubernetes Node Agent...
Apr 14 12:19:03 clusterfuck-control-plane kubelet[217]: I0414 12:19:03.543228     217 dynamic_cafile_content.go:171] "Shutting down controller" name="client-ca-bundle::/etc/kubernetes/pki/ca.crt"
Apr 14 12:19:03 clusterfuck-control-plane systemd[1]: kubelet.service: Deactivated successfully.
Apr 14 12:19:03 clusterfuck-control-plane systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Apr 14 12:19:03 clusterfuck-control-plane systemd[1]: Starting kubelet: The Kubernetes Node Agent...
Apr 14 12:19:03 clusterfuck-control-plane systemd[1]: Started kubelet: The Kubernetes Node Agent.
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: Flag --pod-infra-container-image has been deprecated, will be removed in 1.27. Image garbage collector will get sandbox image information from CRI.
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.685537     664 server.go:198] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: Flag --pod-infra-container-image has been deprecated, will be removed in 1.27. Image garbage collector will get sandbox image information from CRI.
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.689514     664 server.go:412] "Kubelet version" kubeletVersion="v1.26.3"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.689628     664 server.go:414] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.689889     664 server.go:836] "Client rotation is on, will bootstrap in background"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.691040     664 certificate_store.go:130] Loading cert/key pair from "/var/lib/kubelet/pki/kubelet-client-current.pem".
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.691923     664 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/ca.crt"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: W0414 12:19:03.694593     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.698818     664 container_manager_linux.go:267] "Container manager verified user specified cgroup-root exists" cgroupRoot=[kubelet]
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.698898     664 container_manager_linux.go:272] "Creating Container Manager object based on Node Config" nodeConfig={RuntimeCgroupsName: SystemCgroupsName: KubeletCgroupsName: KubeletOOMScoreAdj:-999 ContainerRuntime: CgroupsPerQOS:true CgroupRoot:/kubelet CgroupDriver:systemd KubeletRootDir:/var/lib/kubelet ProtectKernelDefaults:false NodeAllocatableConfig:{KubeReservedCgroupName: SystemReservedCgroupName: ReservedSystemCPUs: EnforceNodeAllocatable:map[pods:{}] KubeReserved:map[] SystemReserved:map[] HardEvictionThresholds:[]} QOSReserved:map[] CPUManagerPolicy:none CPUManagerPolicyOptions:map[] ExperimentalTopologyManagerScope:container CPUManagerReconcilePeriod:10s ExperimentalMemoryManagerPolicy:None ExperimentalMemoryManagerReservedMemory:[] ExperimentalPodPidsLimit:-1 EnforceCPULimits:true CPUCFSQuotaPeriod:100ms ExperimentalTopologyManagerPolicy:none ExperimentalTopologyManagerPolicyOptions:map[]}
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.698925     664 topology_manager.go:134] "Creating topology manager with policy per scope" topologyPolicyName="none" topologyScopeName="container"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.698938     664 container_manager_linux.go:308] "Creating device plugin manager"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.698964     664 state_mem.go:36] "Initialized new in-memory state store"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.703146     664 kubelet.go:398] "Attempting to sync node with API server"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.703203     664 kubelet.go:286] "Adding static pod path" path="/etc/kubernetes/manifests"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.703228     664 kubelet.go:297] "Adding apiserver pod source"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.703238     664 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.706161     664 kuberuntime_manager.go:244] "Container runtime initialized" containerRuntime="containerd" version="v1.6.19-46-g941215f49" apiVersion="v1"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.706531     664 server.go:1186] "Started kubelet"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.710258     664 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.717004     664 volume_manager.go:293] "Starting Kubelet Volume Manager"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.719129     664 desired_state_of_world_populator.go:151] "Desired state populator starts to run"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.722102     664 server.go:161] "Starting to listen" address="0.0.0.0" port=10250
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.722984     664 server.go:451] "Adding debug handlers to kubelet server"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.766984     664 kubelet_network_linux.go:63] "Initialized iptables rules." protocol=IPv4
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.821252     664 kubelet_node_status.go:70] "Attempting to register node" node="clusterfuck-control-plane"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.841395     664 kubelet_network_linux.go:63] "Initialized iptables rules." protocol=IPv6
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.841447     664 status_manager.go:176] "Starting to sync pod status with apiserver"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.841468     664 kubelet.go:2113] "Starting kubelet main sync loop"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: E0414 12:19:03.841653     664 kubelet.go:2137] "Skipping pod synchronization" err="[container runtime status check may not have completed yet, PLEG is not healthy: pleg has yet to be successful]"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.868756     664 kubelet_node_status.go:108] "Node was previously registered" node="clusterfuck-control-plane"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.868878     664 kubelet_node_status.go:73] "Successfully registered node" node="clusterfuck-control-plane"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.878483     664 cpu_manager.go:214] "Starting CPU manager" policy="none"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.878534     664 cpu_manager.go:215] "Reconciling" reconcilePeriod="10s"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.878616     664 state_mem.go:36] "Initialized new in-memory state store"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.878850     664 state_mem.go:88] "Updated default CPUSet" cpuSet=""
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.878879     664 state_mem.go:96] "Updated CPUSet assignments" assignments=map[]
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.878889     664 policy_none.go:49] "None policy: Start"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.880002     664 memory_manager.go:169] "Starting memorymanager" policy="None"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.880061     664 state_mem.go:35] "Initializing new in-memory state store"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.880266     664 state_mem.go:75] "Updated machine memory state"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.890202     664 manager.go:455] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.890495     664 plugin_manager.go:118] "Starting Kubelet Plugin Manager"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.942336     664 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.942462     664 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.943545     664 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:19:03 clusterfuck-control-plane kubelet[664]: I0414 12:19:03.943611     664 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120674     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-etc-ca-certificates\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120751     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-k8s-certs\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120774     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/bc029fa94725104014953f288b5111db-ca-certs\") pod \"kube-apiserver-clusterfuck-control-plane\" (UID: \"bc029fa94725104014953f288b5111db\") " pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120791     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/52a49c1dda96443061d997ca66c5aae7-kubeconfig\") pod \"kube-scheduler-clusterfuck-control-plane\" (UID: \"52a49c1dda96443061d997ca66c5aae7\") " pod="kube-system/kube-scheduler-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120809     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bc029fa94725104014953f288b5111db-etc-ca-certificates\") pod \"kube-apiserver-clusterfuck-control-plane\" (UID: \"bc029fa94725104014953f288b5111db\") " pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120824     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/bc029fa94725104014953f288b5111db-k8s-certs\") pod \"kube-apiserver-clusterfuck-control-plane\" (UID: \"bc029fa94725104014953f288b5111db\") " pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120854     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-ca-certs\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120878     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-kubeconfig\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120900     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-usr-share-ca-certificates\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120923     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-certs\" (UniqueName: \"kubernetes.io/host-path/cf4141b3b06b4295e10fda6cee69dc09-etcd-certs\") pod \"etcd-clusterfuck-control-plane\" (UID: \"cf4141b3b06b4295e10fda6cee69dc09\") " pod="kube-system/etcd-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120947     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bc029fa94725104014953f288b5111db-usr-share-ca-certificates\") pod \"kube-apiserver-clusterfuck-control-plane\" (UID: \"bc029fa94725104014953f288b5111db\") " pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120964     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"flexvolume-dir\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-flexvolume-dir\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.120984     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/ba2bfe9fab65c7374db97567e0331986-usr-local-share-ca-certificates\") pod \"kube-controller-manager-clusterfuck-control-plane\" (UID: \"ba2bfe9fab65c7374db97567e0331986\") " pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.121003     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-data\" (UniqueName: \"kubernetes.io/host-path/cf4141b3b06b4295e10fda6cee69dc09-etcd-data\") pod \"etcd-clusterfuck-control-plane\" (UID: \"cf4141b3b06b4295e10fda6cee69dc09\") " pod="kube-system/etcd-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.121024     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bc029fa94725104014953f288b5111db-usr-local-share-ca-certificates\") pod \"kube-apiserver-clusterfuck-control-plane\" (UID: \"bc029fa94725104014953f288b5111db\") " pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:19:04 clusterfuck-control-plane kubelet[664]: I0414 12:19:04.709673     664 apiserver.go:52] "Watching apiserver"
Apr 14 12:19:05 clusterfuck-control-plane kubelet[664]: I0414 12:19:05.120145     664 desired_state_of_world_populator.go:159] "Finished populating initial desired state of world"
Apr 14 12:19:05 clusterfuck-control-plane kubelet[664]: I0414 12:19:05.129010     664 reconciler.go:41] "Reconciler: start to sync state"
Apr 14 12:19:05 clusterfuck-control-plane kubelet[664]: E0414 12:19:05.318621     664 kubelet.go:1802] "Failed creating a mirror pod for" err="pods \"kube-controller-manager-clusterfuck-control-plane\" already exists" pod="kube-system/kube-controller-manager-clusterfuck-control-plane"
Apr 14 12:19:05 clusterfuck-control-plane kubelet[664]: E0414 12:19:05.510842     664 kubelet.go:1802] "Failed creating a mirror pod for" err="pods \"kube-apiserver-clusterfuck-control-plane\" already exists" pod="kube-system/kube-apiserver-clusterfuck-control-plane"
Apr 14 12:19:05 clusterfuck-control-plane kubelet[664]: E0414 12:19:05.720816     664 kubelet.go:1802] "Failed creating a mirror pod for" err="pods \"kube-scheduler-clusterfuck-control-plane\" already exists" pod="kube-system/kube-scheduler-clusterfuck-control-plane"
Apr 14 12:19:05 clusterfuck-control-plane kubelet[664]: I0414 12:19:05.910965     664 request.go:690] Waited for 1.012749919s due to client-side throttling, not priority and fairness, request: POST:https://clusterfuck-control-plane:6443/api/v1/namespaces/kube-system/pods
Apr 14 12:19:05 clusterfuck-control-plane kubelet[664]: E0414 12:19:05.927706     664 kubelet.go:1802] "Failed creating a mirror pod for" err="pods \"etcd-clusterfuck-control-plane\" already exists" pod="kube-system/etcd-clusterfuck-control-plane"
Apr 14 12:19:06 clusterfuck-control-plane kubelet[664]: I0414 12:19:06.713030     664 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-controller-manager-clusterfuck-control-plane" podStartSLOduration=2.712980526 pod.CreationTimestamp="2023-04-14 12:19:04 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-04-14 12:19:06.334976733 +0000 UTC m=+2.734902718" watchObservedRunningTime="2023-04-14 12:19:06.712980526 +0000 UTC m=+3.112906506"
Apr 14 12:19:07 clusterfuck-control-plane kubelet[664]: I0414 12:19:07.511481     664 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-apiserver-clusterfuck-control-plane" podStartSLOduration=4.511448493 pod.CreationTimestamp="2023-04-14 12:19:03 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-04-14 12:19:07.110909863 +0000 UTC m=+3.510835839" watchObservedRunningTime="2023-04-14 12:19:07.511448493 +0000 UTC m=+3.911374473"
Apr 14 12:19:07 clusterfuck-control-plane kubelet[664]: I0414 12:19:07.915308     664 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-scheduler-clusterfuck-control-plane" podStartSLOduration=4.915273761 pod.CreationTimestamp="2023-04-14 12:19:03 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-04-14 12:19:07.512220553 +0000 UTC m=+3.912146537" watchObservedRunningTime="2023-04-14 12:19:07.915273761 +0000 UTC m=+4.315199741"
Apr 14 12:19:08 clusterfuck-control-plane kubelet[664]: I0414 12:19:08.316658     664 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/etcd-clusterfuck-control-plane" podStartSLOduration=5.316627901 pod.CreationTimestamp="2023-04-14 12:19:03 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-04-14 12:19:07.915755466 +0000 UTC m=+4.315681440" watchObservedRunningTime="2023-04-14 12:19:08.316627901 +0000 UTC m=+4.716553881"
Apr 14 12:19:16 clusterfuck-control-plane kubelet[664]: I0414 12:19:16.886391     664 kuberuntime_manager.go:1114] "Updating runtime config through cri with podcidr" CIDR="10.244.0.0/24"
Apr 14 12:19:16 clusterfuck-control-plane kubelet[664]: I0414 12:19:16.887466     664 kubelet_network.go:61] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.244.0.0/24"
Apr 14 12:19:17 clusterfuck-control-plane kubelet[664]: I0414 12:19:17.649101     664 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:19:17 clusterfuck-control-plane kubelet[664]: I0414 12:19:17.651241     664 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:19:17 clusterfuck-control-plane kubelet[664]: I0414 12:19:17.731873     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/85b97808-cc7f-47bb-86ab-2e2c43ae00fc-lib-modules\") pod \"kube-proxy-49nl7\" (UID: \"85b97808-cc7f-47bb-86ab-2e2c43ae00fc\") " pod="kube-system/kube-proxy-49nl7"
Apr 14 12:19:17 clusterfuck-control-plane kubelet[664]: I0414 12:19:17.731947     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/0e729414-c583-45f8-a7e3-e6794cf27101-xtables-lock\") pod \"kindnet-blcxg\" (UID: \"0e729414-c583-45f8-a7e3-e6794cf27101\") " pod="kube-system/kindnet-blcxg"
Apr 14 12:19:17 clusterfuck-control-plane kubelet[664]: I0414 12:19:17.731966     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/0e729414-c583-45f8-a7e3-e6794cf27101-lib-modules\") pod \"kindnet-blcxg\" (UID: \"0e729414-c583-45f8-a7e3-e6794cf27101\") " pod="kube-system/kindnet-blcxg"
Apr 14 12:19:17 clusterfuck-control-plane kubelet[664]: I0414 12:19:17.731983     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/85b97808-cc7f-47bb-86ab-2e2c43ae00fc-kube-proxy\") pod \"kube-proxy-49nl7\" (UID: \"85b97808-cc7f-47bb-86ab-2e2c43ae00fc\") " pod="kube-system/kube-proxy-49nl7"
Apr 14 12:19:17 clusterfuck-control-plane kubelet[664]: I0414 12:19:17.732003     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/85b97808-cc7f-47bb-86ab-2e2c43ae00fc-xtables-lock\") pod \"kube-proxy-49nl7\" (UID: \"85b97808-cc7f-47bb-86ab-2e2c43ae00fc\") " pod="kube-system/kube-proxy-49nl7"
Apr 14 12:19:17 clusterfuck-control-plane kubelet[664]: I0414 12:19:17.732020     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-r6hds\" (UniqueName: \"kubernetes.io/projected/85b97808-cc7f-47bb-86ab-2e2c43ae00fc-kube-api-access-r6hds\") pod \"kube-proxy-49nl7\" (UID: \"85b97808-cc7f-47bb-86ab-2e2c43ae00fc\") " pod="kube-system/kube-proxy-49nl7"
Apr 14 12:19:17 clusterfuck-control-plane kubelet[664]: I0414 12:19:17.732044     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cni-cfg\" (UniqueName: \"kubernetes.io/host-path/0e729414-c583-45f8-a7e3-e6794cf27101-cni-cfg\") pod \"kindnet-blcxg\" (UID: \"0e729414-c583-45f8-a7e3-e6794cf27101\") " pod="kube-system/kindnet-blcxg"
Apr 14 12:19:17 clusterfuck-control-plane kubelet[664]: I0414 12:19:17.732062     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-shcb9\" (UniqueName: \"kubernetes.io/projected/0e729414-c583-45f8-a7e3-e6794cf27101-kube-api-access-shcb9\") pod \"kindnet-blcxg\" (UID: \"0e729414-c583-45f8-a7e3-e6794cf27101\") " pod="kube-system/kindnet-blcxg"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.004470     664 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-proxy-49nl7" podStartSLOduration=5.004382984 pod.CreationTimestamp="2023-04-14 12:19:17 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-04-14 12:19:18.956106134 +0000 UTC m=+15.355878986" watchObservedRunningTime="2023-04-14 12:19:22.004382984 +0000 UTC m=+18.404155839"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.203957     664 kubelet_node_status.go:493] "Fast updating node status as it just became ready"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.246620     664 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kindnet-blcxg" podStartSLOduration=-9.223372031608183e+09 pod.CreationTimestamp="2023-04-14 12:19:17 +0000 UTC" firstStartedPulling="2023-04-14 12:19:18.248321798 +0000 UTC m=+14.648094648" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-04-14 12:19:22.005344721 +0000 UTC m=+18.405117583" watchObservedRunningTime="2023-04-14 12:19:22.246592249 +0000 UTC m=+18.646365108"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.246840     664 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: W0414 12:19:22.250092     664 reflector.go:424] object-"kube-system"/"coredns": failed to list *v1.ConfigMap: configmaps "coredns" is forbidden: User "system:node:clusterfuck-control-plane" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'clusterfuck-control-plane' and this object
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: E0414 12:19:22.250640     664 reflector.go:140] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "coredns" is forbidden: User "system:node:clusterfuck-control-plane" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'clusterfuck-control-plane' and this object
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.280865     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-qdngf\" (UniqueName: \"kubernetes.io/projected/2cccd300-ad54-43eb-a30e-7e46e0a5546f-kube-api-access-qdngf\") pod \"coredns-787d4945fb-jt4g6\" (UID: \"2cccd300-ad54-43eb-a30e-7e46e0a5546f\") " pod="kube-system/coredns-787d4945fb-jt4g6"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.280982     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/2cccd300-ad54-43eb-a30e-7e46e0a5546f-config-volume\") pod \"coredns-787d4945fb-jt4g6\" (UID: \"2cccd300-ad54-43eb-a30e-7e46e0a5546f\") " pod="kube-system/coredns-787d4945fb-jt4g6"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.290403     664 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.308872     664 topology_manager.go:210] "Topology Admit Handler"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.381616     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-7z5sk\" (UniqueName: \"kubernetes.io/projected/d88d469e-6d93-4bb0-8d5e-83f2e7dab652-kube-api-access-7z5sk\") pod \"local-path-provisioner-75f5b54ffd-q6wb9\" (UID: \"d88d469e-6d93-4bb0-8d5e-83f2e7dab652\") " pod="local-path-storage/local-path-provisioner-75f5b54ffd-q6wb9"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.381667     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/1163697a-ed1d-465b-842a-e45b59a37413-config-volume\") pod \"coredns-787d4945fb-cgh87\" (UID: \"1163697a-ed1d-465b-842a-e45b59a37413\") " pod="kube-system/coredns-787d4945fb-cgh87"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.381697     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/d88d469e-6d93-4bb0-8d5e-83f2e7dab652-config-volume\") pod \"local-path-provisioner-75f5b54ffd-q6wb9\" (UID: \"d88d469e-6d93-4bb0-8d5e-83f2e7dab652\") " pod="local-path-storage/local-path-provisioner-75f5b54ffd-q6wb9"
Apr 14 12:19:22 clusterfuck-control-plane kubelet[664]: I0414 12:19:22.381809     664 reconciler_common.go:253] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-fpmhr\" (UniqueName: \"kubernetes.io/projected/1163697a-ed1d-465b-842a-e45b59a37413-kube-api-access-fpmhr\") pod \"coredns-787d4945fb-cgh87\" (UID: \"1163697a-ed1d-465b-842a-e45b59a37413\") " pod="kube-system/coredns-787d4945fb-cgh87"
Apr 14 12:19:26 clusterfuck-control-plane kubelet[664]: I0414 12:19:26.686197     664 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/coredns-787d4945fb-cgh87" podStartSLOduration=9.686159933999999 pod.CreationTimestamp="2023-04-14 12:19:17 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-04-14 12:19:26.615838287 +0000 UTC m=+23.015611148" watchObservedRunningTime="2023-04-14 12:19:26.686159934 +0000 UTC m=+23.085932797"
Apr 14 12:19:26 clusterfuck-control-plane kubelet[664]: I0414 12:19:26.805210     664 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/coredns-787d4945fb-jt4g6" podStartSLOduration=9.805174324 pod.CreationTimestamp="2023-04-14 12:19:17 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-04-14 12:19:26.7301764 +0000 UTC m=+23.129949262" watchObservedRunningTime="2023-04-14 12:19:26.805174324 +0000 UTC m=+23.204947178"
Apr 14 12:19:27 clusterfuck-control-plane kubelet[664]: I0414 12:19:27.041572     664 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="local-path-storage/local-path-provisioner-75f5b54ffd-q6wb9" podStartSLOduration=-9.2233720268133e+09 pod.CreationTimestamp="2023-04-14 12:19:17 +0000 UTC" firstStartedPulling="2023-04-14 12:19:23.055198625 +0000 UTC m=+19.454971477" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-04-14 12:19:27.041209169 +0000 UTC m=+23.440982023" watchObservedRunningTime="2023-04-14 12:19:27.041476133 +0000 UTC m=+23.441248995"
Apr 14 12:24:03 clusterfuck-control-plane kubelet[664]: W0414 12:24:03.880035     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:29:03 clusterfuck-control-plane kubelet[664]: W0414 12:29:03.878092     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:34:03 clusterfuck-control-plane kubelet[664]: W0414 12:34:03.876302     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:39:03 clusterfuck-control-plane kubelet[664]: W0414 12:39:03.870126     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:44:03 clusterfuck-control-plane kubelet[664]: W0414 12:44:03.866942     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:49:03 clusterfuck-control-plane kubelet[664]: W0414 12:49:03.864911     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:54:03 clusterfuck-control-plane kubelet[664]: W0414 12:54:03.862520     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 12:59:03 clusterfuck-control-plane kubelet[664]: W0414 12:59:03.861440     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:04:03 clusterfuck-control-plane kubelet[664]: W0414 13:04:03.859073     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:09:03 clusterfuck-control-plane kubelet[664]: W0414 13:09:03.861692     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:14:03 clusterfuck-control-plane kubelet[664]: W0414 13:14:03.829853     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:19:03 clusterfuck-control-plane kubelet[664]: W0414 13:19:03.823994     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:24:03 clusterfuck-control-plane kubelet[664]: W0414 13:24:03.821036     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:29:03 clusterfuck-control-plane kubelet[664]: W0414 13:29:03.816550     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:34:03 clusterfuck-control-plane kubelet[664]: W0414 13:34:03.806506     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:39:03 clusterfuck-control-plane kubelet[664]: W0414 13:39:03.802006     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Apr 14 13:44:03 clusterfuck-control-plane kubelet[664]: W0414 13:44:03.796944     664 sysinfo.go:203] Nodes topology is not available, providing CPU topology
